{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 4 Part III: Convolutional Neural Newtorks\n",
    "\n",
    "\n",
    "## 2D Convolutions\n",
    "Actual convolution of a two dimensional signal with a \"patch\":\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "  0.0 & 0.0 & 5.0 & 13.0 & 9.0 & 1.0 & 0.0 & 0.0\\\\\n",
    "  0.0 & 0.0 & 13.0 & 15.0 & 10.0 & 15.0 & 5.0 & 0.0\\\\\n",
    "  0.0 & 3.0 & 15.0 & 2.0 & 0.0 & 11.0 & 8.0 & 0.0\\\\\n",
    "  0.0 & 4.0 & 12.0 & 0.0 & 0.0 & 8.0 & 8.0 & 0.0\\\\\n",
    "  0.0 & 5.0 & 8.0 & 0.0 & 0.0 & 9.0 & 8.0 & 0.0\\\\\n",
    "  0.0 & 4.0 & 11.0 & 0.0 & 1.0 & 12.0 & 7.0 & 0.0\\\\\n",
    "  0.0 & 2.0 & 14.0 & 5.0 & 10.0 & 12.0 & 0.0 & 0.0\\\\\n",
    "  0.0 & 0.0 & 6.0 & 13.0 & 10.0 & 0.0 & 0.0 & 0.0\\\\\n",
    "\\end{pmatrix} \\ast \\begin{pmatrix}\n",
    "  1 & 1 & -1\\\\\n",
    "  -1 & 1 & 1\\\\\n",
    "  -1 & -1 & 1\\\\\n",
    "\\end{pmatrix} = \\begin{pmatrix}\n",
    "0.0 & -6.0 & -12.0 & 22.0 & 47.0 & 18.0\\\\\n",
    "-9.0 & -4.0 & -7.0 & -11.0 & 9.0 & 29.0\\\\\n",
    "-13.0 & 5.0 & 17.0 & -8.0 & -2.0 & 18.0\\\\\n",
    "-4.0 & 12.0 & 10.0 & -4.0 & 3.0 & 12.0\\\\\n",
    "-4.0 & 29.0 & 19.0 & -3.0 & -9.0 & 8.0\\\\\n",
    "-21.0 & 23.0 & 36.0 & -13.0 & -6.0 & 17.0\\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "A \"sliding\" convolution is a little easier to understand:\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "  0.0 & 0.0 & 5.0 & 13.0 & 9.0 & 1.0 & 0.0 & 0.0\\\\\n",
    "  0.0 & 0.0 & 13.0 & 15.0 & 10.0 & 15.0 & 5.0 & 0.0\\\\\n",
    "  0.0 & 3.0 & 15.0 & 2.0 & 0.0 & 11.0 & 8.0 & 0.0\\\\\n",
    "  0.0 & 4.0 & 12.0 & 0.0 & 0.0 & 8.0 & 8.0 & 0.0\\\\\n",
    "  0.0 & 5.0 & 8.0 & 0.0 & 0.0 & 9.0 & 8.0 & 0.0\\\\\n",
    "  0.0 & 4.0 & 11.0 & 0.0 & 1.0 & 12.0 & 7.0 & 0.0\\\\\n",
    "  0.0 & 2.0 & 14.0 & 5.0 & 10.0 & 12.0 & 0.0 & 0.0\\\\\n",
    "  0.0 & 0.0 & 6.0 & 13.0 & 10.0 & 0.0 & 0.0 & 0.0\\\\\n",
    "\\end{pmatrix} \\star \\begin{pmatrix}\n",
    "  1 & -1 & -1\\\\\n",
    "  1 & 1 & -1\\\\\n",
    "  -1 & 1 & 1\\\\\n",
    "\\end{pmatrix} = \\begin{pmatrix}\n",
    "0.0 & -6.0 & -12.0 & 22.0 & 47.0 & 18.0\\\\\n",
    "-9.0 & -4.0 & -7.0 & -11.0 & 9.0 & 29.0\\\\\n",
    "-13.0 & 5.0 & 17.0 & -8.0 & -2.0 & 18.0\\\\\n",
    "-4.0 & 12.0 & 10.0 & -4.0 & 3.0 & 12.0\\\\\n",
    "-4.0 & 29.0 & 19.0 & -3.0 & -9.0 & 8.0\\\\\n",
    "-21.0 & 23.0 & 36.0 & -13.0 & -6.0 & 17.0\\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "## Group Problems\n",
    "\n",
    "Compute the following convolutions:\n",
    "\n",
    "1. $\\begin{pmatrix} 0 & 1 & 2 & 1\\\\ 1 & 1 &2 & 0\\\\ 0 & 1 & 1 & 0\\\\ 1 & 0 & 2 & 1\\end{pmatrix} \\ast \\begin{pmatrix}1 & 1 \\\\ 1 & 1\\end{pmatrix}$\n",
    "2. $\\begin{pmatrix} 0 & 1 & 2 & 1\\\\ 1 & 1 &2 & 0\\\\ 0 & 1 & 1 & 0\\\\ 1 & 0 & 2 & 1\\end{pmatrix} \\ast \\begin{pmatrix}1 & 1 \\\\ -1 & -1\\end{pmatrix}$\n",
    "3. $\\begin{pmatrix} 0 & 1 & 2 & 1\\\\ 1 & 1 &2 & 0\\\\ 0 & 1 & 1 & 0\\\\ 1 & 0 & 2 & 1\\end{pmatrix} \\ast \\begin{pmatrix}1 & -1 \\\\ 1 & -1\\end{pmatrix}$\n",
    "4. $\\begin{pmatrix} 0 & 1 & 2 & 1\\\\ 1 & 1 &2 & 0\\\\ 0 & 1 & 1 & 0\\\\ 1 & 0 & 2 & 1\\end{pmatrix} \\ast \\begin{pmatrix}1 & -1 \\\\ -1 & 1\\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABAlJREFUeJzt3dFNqmkUhtGPyTRAC1gCtgIlaAlagr1YwqEEacESpIR/\nKpiYSY579DlrXRNeAzz5b0z2btu2BTT99X//AcDXETiECRzCBA5hAocwgUOYwCFM4BAmcAj7+yve\ndLfbJf897nQ6je69vLyMbV0ul7Gt5+fnsa3b7Ta2NW3btt1nr/EEhzCBQ5jAIUzgECZwCBM4hAkc\nwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ9iX\nnC6qmjwltNZah8NhbGu/349tfXx8jG2dz+exrbXWen19Hd37jCc4hAkcwgQOYQKHMIFDmMAhTOAQ\nJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwn78\n6aLj8Ti2NXlKaK217u7uxrbe39/Htn79+jW2Nfn7WMvpImCQwCFM4BAmcAgTOIQJHMIEDmEChzCB\nQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BD242+T\n7ff7sa3r9Tq2tdbsvbBJ05/jn8wTHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAh\nTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmFOF/0Hl8tlbKts8ju73W5jW9+R\nJziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKH\nMIFDmMAhTOAQJnAIEziECRzCfvzposnTNMfjcWxr2uQ5ocnP8fX1dWzrO/IEhzCBQ5jAIUzgECZw\nCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEC\nhzCBQ9hu27bf/6a73e9/039xOBymptbb29vY1lprPT4+jm2dTqexrcnv7P7+fmxr2rZtu89e4wkO\nYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzg\nECZwCBM4hAkcwgQOYQKHMIFD2I+/TTbp4eFhdO/p6Wls63q9jm2dz+exrTK3yeAPJ3AIEziECRzC\nBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAh\nTOAQJnAI+5LTRcD34AkOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJ\nHMIEDmEChzCBQ5jAIUzgECZwCBM4hP0DVJVS9XOb5i4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12af93400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ8AAAD8CAYAAABpXiE9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAA0pJREFUeJzt2sFpA0EQRUG12PxTbmcg4WfMrERVBJ85PPows7sPgN96\nnh4AfCbxABLxABLxABLxABLxABLxABLxABLxAJLr9IA3fH/lT2bm9ITb2930SC4PIBEPIBEPIBEP\nIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEP\nIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEP\nIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEP\nIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEPIBEPILlOD3hlZk5PuLXdPT3h9rzR/3F5AIl4\nAIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4\nAIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4\nAIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4\nAIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AMl1egDdzJyecHu7e3rC13J5AIl4\nAIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4\nAIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4\nAIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4\nAIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AIl4AMns7ukNwAdyeQCJeACJeACJ\neACJeACJeACJeACJeACJeACJeACJeACJeACJeACJeACJeACJeACJeACJeACJeACJeACJeACJeACJ\neADJD8xTFPQbMnGfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12b5d2fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABBtJREFUeJzt2iFOZFsYRtGmwwAIKQWuPDh8JWURjACHZBA4PCNgJswA\ngSDBkwCKEHy1vrmCwOt6p7Ozlr7585mdY+7OZrP5BTT9Hj0A2B6BQ5jAIUzgECZwCBM4hAkcwgQO\nYQKHsN1tHD07O/unfo97fX0dPWHm5eVl9ISJq6ur0RMmzs/PR0+Yubm5GT1h4vLycuerb7zgECZw\nCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEC\nhzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziE7Ww2m79+9Ojo6O8f/Q8Wi8Xo\nCTOfn5+jJ0y8v7+PnjBxeno6esLMv7ZpvV7vfPWNFxzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIE\nDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM\n4BAmcAgTOIQJHMIEDmEChzCBQ9juNo5+fHxs4+yPnZycjJ4wc3x8PHrCxO3t7egJE4+Pj6MnzCyX\ny9ETJtbr9ZffeMEhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jA\nIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAjb3cbR\n5XK5jbM/dnh4OHrCzPPz8+gJE3t7e6MnTOzv74+eMPP29jZ6wrd5wSFM4BAmcAgTOIQJHMIEDmEC\nhzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAm\ncAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCNsdPeD/sFqtRk+YeXp6Gj1h4v7+fvSEiYeHh9ETZhaL\nxegJ3+YFhzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzCBA5hAocwgUOY\nwCFM4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQtruNo3d3\nd9s4+2MXFxejJ8ysVqvREyaur69HT5g4ODgYPWFmuVyOnvBtXnAIEziECRzCBA5hAocwgUOYwCFM\n4BAmcAgTOIQJHMIEDmEChzCBQ5jAIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAhTOAQJnAIEziECRzC\nBA5hAocwgUOYwCFM4BAmcAgTOIQJHMJ2NpvN6A3AlnjBIUzgECZwCBM4hAkcwgQOYQKHMIFDmMAh\nTOAQJnAIEziECRzCBA5hAocwgUOYwCFM4BAmcAgTOIQJHMIEDmECh7A/DPZBAnRJ7FUAAAAASUVO\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12b5ee710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.datasets as db\n",
    "\n",
    "def conv2d(h, x):\n",
    "    '''\n",
    "    Direct computation of 2D convolution without padding\n",
    "    :param h: 2D numpy array, the convolutional filter\n",
    "    :param x: 2D numpy array, signal to be convolved\n",
    "    :return: convolution\n",
    "    '''\n",
    "    m = x.shape[0] - h.shape[0] + 1\n",
    "    n = x.shape[1] - h.shape[1] + 1\n",
    "    y = np.zeros((m, n))\n",
    "    f = np.fliplr(np.flipud(x))\n",
    "    for i in range(m):\n",
    "        for j in range(n):\n",
    "            y[i, j] = np.sum(h * f[i:(i+h.shape[0]), j:(j+h.shape[1])])\n",
    "    return np.fliplr(np.flipud(y))\n",
    "\n",
    "x = db.load_digits()\n",
    "# im =  np.reshape(X.images[0,:,:], (16, 16))\n",
    "im = x.images[0,:,:]\n",
    "h = np.array([[1, 1, -1], [-1, 1, 1], [-1, -1, 1]])\n",
    "im_padded = np.zeros((16, 16))\n",
    "im_padded[4:12, 4:12] = im\n",
    "h_padded = np.zeros((16, 16))\n",
    "#h_padded[4:7, 4:7] = h\n",
    "h_padded[:3,:3] = h\n",
    "y = conv2d(h, im)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.imshow(im, cmap='gray', interpolation='nearest')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(2)\n",
    "plt.imshow(h, cmap='gray', interpolation='nearest')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(3)\n",
    "plt.imshow(y, cmap='gray', interpolation='nearest')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "step 0, training accuracy 0.1\n",
      "step 100, training accuracy 0.8\n",
      "step 200, training accuracy 0.8\n",
      "step 300, training accuracy 0.94\n",
      "step 400, training accuracy 0.9\n",
      "step 500, training accuracy 0.8\n",
      "step 600, training accuracy 0.88\n",
      "step 700, training accuracy 0.92\n",
      "step 800, training accuracy 0.92\n",
      "step 900, training accuracy 0.9\n",
      "test accuracy 0.9476\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\n",
    "\"\"\"A very simple MNIST classifier.\n",
    "See extensive documentation at\n",
    "http://tensorflow.org/tutorials/mnist/beginners/index.md\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "# Import data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Functions for randomly initialization convolutional layer weights and biases\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# Functions for generating pooling layers\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME') # Same means zero pad\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def main(_):\n",
    "    mnist = input_data.read_data_sets('./MNIST_data', one_hot=True) # Loads the mnist dataset\n",
    "\n",
    "    # Initialize the session\n",
    "    sess = tf.InteractiveSession()\n",
    "\n",
    "    # Create the model\n",
    "    x = tf.placeholder(tf.float32, [None, 784])\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "    x_image = tf.reshape(x, [-1, 28, 28, 1]) # -1 means that the first index is illegal\n",
    "\n",
    "    # Variables for first convolutional layer\n",
    "    W_conv1 = weight_variable([5, 5, 1, 16]) #16 5 by 5 convolutional filters\n",
    "    b_conv1 = bias_variable([16])\n",
    "\n",
    "    # Response from first convolutional layer\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1) # Note that relu is indicating usage of rectified linear units\n",
    "    # h_conv1 holds onto 32 28 by 28 images obtained by applying zero padding to change 28 by 28 images to 32 by 32 images\n",
    "    h_pool1 = max_pool_2x2(h_conv1) # Pooling applied\n",
    "    # Expected behavior is that h_pool1 consists of 16 14 by 14 images\n",
    "\n",
    "    # Variables for the second convolutional layer\n",
    "    W_conv2 = weight_variable([5, 5, 16, 32]) # Note that convolution over a stack of images involves a \"convolutional column\"\n",
    "    # 5 by 5 patches, we expect 32 \"images\" resulting from convolution, and we make 32 more convolutional filters\n",
    "    b_conv2 = bias_variable([32])\n",
    "\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "    h_pool2 = max_pool_2x2(h_conv2) # Pooling applied -- reduces 14 by 14 images to 7 by 7 images\n",
    "\n",
    "    # We now have 32, 7 by 7 images because of successive convolution and max pooling\n",
    "\n",
    "    # Weights for the third layer, which is densely/fully connected\n",
    "    W_fc1 = weight_variable([7 * 7 * 32, 256])\n",
    "    b_fc1 = bias_variable([256])\n",
    "\n",
    "    # Response from the densely connected layer\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 32]) # Vectorizing the 32 7 by 7 images\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "    # Weights for the readout layer\n",
    "    W_fc2 = weight_variable([256, 10])\n",
    "    b_fc2 = bias_variable([10])\n",
    "\n",
    "    y_conv = tf.matmul(h_fc1, W_fc2) + b_fc2 # Final output\n",
    "\n",
    "    # Cross entropy applied to softmax outputs\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "    # Define the training step with step size 1e-4\n",
    "    train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "    correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1)) # Note, softmax is unnecessary for classification\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    saver = tf.train.Saver() # Create saver\n",
    "\n",
    "    for i in range(1000):\n",
    "        batch = mnist.train.next_batch(50)\n",
    "        if i % 100 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={x: batch[0], y_: batch[1]})\n",
    "            print(\"step %d, training accuracy %g\" % (i, train_accuracy))\n",
    "        train_step.run(feed_dict={x: batch[0], y_: batch[1]})\n",
    "\n",
    "    print(\"test accuracy %g\" % accuracy.eval(feed_dict={x: mnist.test.images, y_: mnist.test.labels}))\n",
    "\n",
    "    save_path = saver.save(sess, \"./model/model.ckpt\") # Save model\n",
    "    sess.close()\n",
    "    \n",
    "# Run the code\n",
    "#parser = argparse.ArgumentParser()\n",
    "#parser.add_argument('--data_dir', type=str, default='/tmp/tensorflow/mnist/input_data',help='Directory for storing input data')\n",
    "#FLAGS, unparsed = parser.parse_known_args()\n",
    "#tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\n",
    "\n",
    "main(_)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
