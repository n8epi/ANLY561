{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Part IX: Support Vector Machines and Duality\n",
    "\n",
    "Support Vector Machines (SVMs) are an excellent tool for classification that also allow us to get a deep example of convex optimization. To motivate SVMs, we consider the problem of separating two sets of data using a line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEKCAYAAAASByJ7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCTAQJEkdA0GSBBgIkqSOgSBJAuD/APlaVSh7ew2OAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109993a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def random_circle(N):\n",
    "    x = np.reshape(rd.randn(N*2), (N, 2))\n",
    "    for i in range(N):\n",
    "        x[i,:] = x[i,:]/np.sqrt(np.sum(x[i,:]**2))\n",
    "    return x\n",
    "\n",
    "def random_radius(N, R=1):\n",
    "    r = rd.rand(N)\n",
    "    return R*np.sqrt(r) # This ensures uniform sampling from the disc\n",
    "    \n",
    "\n",
    "def random_disc(N, mu=[0,0], R=1):\n",
    "    x = random_circle(N)\n",
    "    r = random_radius(N, R=R)\n",
    "    for i in range(N):\n",
    "        x[i, :] = r[i] * x[i, :] + mu\n",
    "    return x\n",
    "\n",
    "N = 10\n",
    "\n",
    "X = random_disc(N, mu=[-2, -2])\n",
    "Y = random_disc(N, mu=[2, 2])\n",
    "\n",
    "plt.scatter(X[:,0], X[:,1])\n",
    "plt.scatter(Y[:,0], Y[:,1])\n",
    "plt.plot([-4, 4], [0, 0])\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The above code produces two types of data: \"blue\" data drawn uniformly from a disc of radius one centered at $(-2,-2)$, and \"orange\" data drawn uniformly from a disc of radius one centered at $(2,2)$. We'll associate the \"blue\" data with the label $-1$ and the orange data with the label $+1$. We see that we can easily separate this data using the following rule: if $y<0$, then the label should be $-1$, and if $0<y$ then the label should be $+1$. However, we could have just as well separated the data using the rule that $x+y<0.5$ gives the label $-1$ and $0.5<x+y$ gives the label $+1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEKCAYAAAASByJ7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109899ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:,0], X[:,1])\n",
    "plt.scatter(Y[:,0], Y[:,1])\n",
    "plt.plot([-4, 4], [4.5, -3.5])\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that both these rules have the form $ax+by+c<0$ implies the label $-1$ and $ax+by+c>0$ implies the label $+1$ for some $a, b, c\\in\\mathbb{R}$. Now, let's try to make our decision rule more *robust*. Let's demand that $ax+by+c\\leq-1$ for data labeled with $-1$'s and $ax+by+c\\geq +1$ for data labeled with $+1$'s. We see that $y\\leq -1$ and $y\\geq 1$ become the new rules for the first separating line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEKCAYAAAASByJ7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1098e1278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:,0], X[:,1])\n",
    "plt.scatter(Y[:,0], Y[:,1])\n",
    "plt.plot([-4, 4], [0, 0])\n",
    "plt.plot([-4, 4], [1, 1], '--')\n",
    "plt.plot([-4, 4], [-1, -1], '--')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the second separating line, we have $x+y-1/2\\leq-1$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEKCAYAAAASByJ7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyVAgiIgIoEAQEZGM/w9i/PXEC6gKLwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cff3cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X[:,0], X[:,1])\n",
    "plt.scatter(Y[:,0], Y[:,1])\n",
    "plt.plot([-4, 4], [4.5, -3.5])\n",
    "plt.plot([-4, 4], [5.5, -2.5], '--')\n",
    "plt.plot([-4, 4], [3.5, -4.5], '--')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the distance between the gap between the cutoff lines (the orange and green dashed lines) is larger for the first separating line and smaller for the second separating line. Let's compute the width of this gap, which is also known as the *margin* of the separating line. Geometrically, the width of this gap is twice the distance from a point on the line $ax+by+c=0$ to the nearest point on the line $ax+by+c=1$. So, suppose $(x^{(0)}, y^{(0)})$ satisfies $ax^{(0)}+by^{(0)}+c=0$ and let's find $(x^\\ast, y^\\ast)$ solving\n",
    "\n",
    "$$\n",
    "\\min (x^{(0)}-x)^2 + (y^{(0)}-y)^2\\text{ subject to } ax + by +c =1.\n",
    "$$\n",
    "\n",
    "Using Lagrange multipliers, we immediately have that\n",
    "\n",
    "$$\n",
    "2\\begin{pmatrix}\n",
    "x-x^{(0)}\\\\ y-y^{(0)}\n",
    "\\end{pmatrix}=\\lambda \\begin{pmatrix} a\\\\ b\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "for some $\\lambda$. Thus,\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "x\\\\ y\n",
    "\\end{pmatrix}=\\frac{\\lambda}{2} \\begin{pmatrix} a\\\\ b\\end{pmatrix} + \\begin{pmatrix} x^{(0)}\\\\ y^{(0)}\\end{pmatrix} = \\begin{pmatrix}\n",
    "\\frac{\\lambda}{2} a + x^{(0)}\\\\\n",
    "\\frac{\\lambda}{2} b + y^{(0)}\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Plugging these values into the contstraint $ax+by+c=1$ gives us\n",
    "\n",
    "$$\n",
    "1=a\\left(\\frac{\\lambda}{2} a + x^{(0)}\\right) + b\\left(\\frac{\\lambda}{2} b + y^{(0)}\\right) + c =\\frac{\\lambda}{2}(a^2+b^2) + ax^{(0)} + by^{(0)}+c = \\frac{\\lambda}{2}(a^2+b^2) + 0=\\frac{\\lambda}{2}(a^2+b^2)\n",
    "$$\n",
    "\n",
    "and hence $\\lambda = \\frac{2}{a^2+b^2}$. Observing that this program is convex and solving the Lagrange conditions is sufficient for optimality, we have that\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "x^\\ast\\\\\n",
    "y^\\ast\n",
    "\\end{pmatrix} = \\frac{1}{a^2+b^2}\\begin{pmatrix} a\\\\ b\\end{pmatrix} + \\begin{pmatrix} x^{(0)}\\\\ y^{(0)}\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "is the minimizer with minimum value $\\frac{1}{a^2+b^2}$. Twice this number, $\\frac{2}{a^2+b^2}$ gives us the margin.\n",
    "\n",
    "So, we conclude that the first line has a margin of $2/(1^2+0^2)=2$ and the second line has a margin of $2/(1^2+1^2)=1$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum Margin Separating Lines\n",
    "\n",
    "The width of the margin is something that we can attempt to optimize. In particular, it would be nice to have a separating line which makes this margin as large as possible subject to the constraints that $ax+by+c\\leq -1$ on the data with $-1$ labels and $ax+by+c\\geq 1$ on the data with $+1$ labels. Let's suppose our data is of the form $\\{(x^{(i)}, y^{(i)}, z^{(i)})\\}_{i=1}^N\\subset \\mathbb{R}^2\\times\\{-1,1\\}$ where $z_i=\\pm1$ is the label of the data point $(x^{(i)}, y^{(i)})$.\n",
    "\n",
    "$$\n",
    "\\max_{a,b,c} \\frac{2}{a^2+b^2} \\text{ subject to } 1-z_i(ax^{(i)}+by^{(i)}+c)\\leq 0\\text{ for }i=1,\\ldots, N.\n",
    "$$\n",
    "\n",
    "where we note that $1-z_i(ax^{(i)}+by^{(i)}+c)\\leq 0$ implies\n",
    "\n",
    "$$\n",
    "1-z_i(ax^{(i)}+by^{(i)}+c)=1+ax^{(i)}+by^{(i)}+c\\leq 0\n",
    "$$\n",
    "\n",
    "when $z_i=-1$, and hence the constraint is equivalent to $ax^{(i)}+by^{(i)}+c\\leq-1$ when $z_i=-1$. Similarly, the constraint $1-z_i(ax^{(i)}+by^{(i)}+c)\\leq 0$ is equivalent to $1\\leq ax^{(i)}+by^{(i)}+c$ when $z_i=1$.\n",
    "\n",
    "Observing that $t\\mapsto 1/t$ is an order inverting map on the positive real numbers, we see that this maximization problem is equivalent to the minimization problem\n",
    "\n",
    "$$\n",
    "\\min_{a,b,c} \\frac{1}{2}(a^2+b^2) \\text{ subject to } 1-z_i(ax^{(i)}+by^{(i)}+c)\\leq 0\\text{ for }i=1,\\ldots, N.\n",
    "$$\n",
    "\n",
    "One can verify that the Hessian of the objective function with respect to the variables $a$, $b$, and $c$ is the constant matrix\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "1 & 0 & 0\\\\\n",
    "0 & 1 & 0\\\\\n",
    "0 & 0 & 0\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "This is a positive semidefinite matrix, so the objective function is convex, and the inequality constraint functions are all convex as well because they are affine functions of $a$, $b$, and $c$. We are therefore dealing with a convex optimization program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duality\n",
    "\n",
    "Given a program\n",
    "\n",
    "$$\n",
    "\\min f({\\bf x})\\text{ subject to } g_i({\\bf x})=0, h_j({\\bf x})\\leq 0\\text{ for }i=1,\\ldots, n;j=1,\\ldots, m\n",
    "$$\n",
    "\n",
    "with functions $f, g_i, h_j:\\mathbb{R}^d\\rightarrow\\mathbb{R}$, the **Lagrangian** is the function $\\mathcal{L}:\\mathbb{R}^d\\times\\mathbb{R}^n\\times\\mathbb{R}^m\\rightarrow\\mathbb{R}$ given by\n",
    "\n",
    "$$\n",
    "\\mathcal{L}({\\bf x}, \\lambda, \\mu) = f({\\bf x}) +\\sum_{i=1}^n \\lambda_i g_i({\\bf x}) + \\sum_{j=1}^m \\mu_j h_j({\\bf x}),\n",
    "$$\n",
    "\n",
    "where $\\lambda$ and $\\mu$ are the **dual variables**. The **Lagrange dual function** is \n",
    "\n",
    "$$\n",
    "\\ell(\\lambda,\\mu)=\\min_{{\\bf x}\\in \\mathbb{R}^d} \\mathcal{L}({\\bf x},\\lambda,\\mu).\n",
    "$$\n",
    "\n",
    "When this minimization program is unbounded below, we set $\\ell(\\lambda,\\mu)=-\\infty$. \n",
    "\n",
    "#### Notation: Recall that dual feasibility requires that $\\mu_j\\geq0$ for all $j=1,\\ldots, m$. We will use the notation $0\\preceq \\mu$ to specify that this system of inequalities holds. We also let $p^\\ast$ denote the minimum value of the original (or, **primal**) program.\n",
    "\n",
    "#### Theorem (Weak Duality): If $\\lambda\\in\\mathbb{R}^n$, $\\mu\\in\\mathbb{R}^m$, and $0\\preceq \\mu$, then $\\ell(\\lambda,\\mu)\\leq p^\\ast$. \n",
    "\n",
    "The proof is simple. Suppose $\\widetilde{\\bf x}$ is feasible so that $g_i({\\bf x})=0$ and $h_j({\\bf x})\\leq 0$ for all $i=1,\\ldots, n$ and $j=1,\\ldots, m$. Then\n",
    "\n",
    "$$\n",
    "\\ell(\\lambda,\\mu)=\\min_{{\\bf x}\\in \\mathbb{R}^d} \\mathcal{L}({\\bf x},\\lambda,\\mu)\\leq \\mathcal{L}(\\widetilde{\\bf x},\\lambda,\\mu)=f(\\widetilde{\\bf x}) +\\sum_{i=1}^n \\lambda_i g_i(\\widetilde{\\bf x}) + \\sum_{j=1}^m \\mu_j h_j(\\widetilde{\\bf x})=f(\\widetilde{\\bf x}) +\\sum_{i=1}^n \\lambda_i\\cdot 0+ \\sum_{j=1}^m \\mu_j h_j(\\widetilde{\\bf x})=f(\\widetilde{\\bf x}) + \\sum_{j=1}^m \\mu_j h_j(\\widetilde{\\bf x})\\leq f(\\widetilde{\\bf x})\n",
    "$$\n",
    "\n",
    "since $\\mu_j\\geq 0$ and $h_j(\\widetilde{\\bf x})\\leq 0$ ($\\widetilde{\\bf x}\\in X$) implies $\\mu_j h_j(\\widetilde{\\bf x})\\leq 0$ for all $j=1,\\ldots, m$. Now, $\\ell(\\lambda, \\mu)\\leq f(\\widetilde{\\bf x})$ for all feasible $\\widetilde{\\bf x}$, so we must conclude that $\\ell(\\lambda,\\mu)\\leq p^\\ast$.\n",
    "\n",
    "### The Lagrange Dual Problem\n",
    "\n",
    "The **Lagrange dual problem** to an optimization program is\n",
    "\n",
    "$$\n",
    "\\max \\ell(\\lambda,\\mu)\\text{ subject to } 0\\preceq \\mu.\n",
    "$$\n",
    "\n",
    "The optimal value of this program will be denoted $d^\\ast$. Another way to state weak duality is that $d^\\ast\\leq p^\\ast$. We will refer to the quantity $p^\\ast-d^\\ast$ as the **duality gap**. If $d^\\ast=p^\\ast$ (equivalent to the duality gap being $0$), then we will say that **strong duality** holds. The following fact is useful because it is sometimes easier to solve the dual program.\n",
    "\n",
    "It turns out that $\\ell(\\lambda, \\mu)$ is always a **concave** function, even if the primal program was not convex. Thus, $-\\ell(\\lambda,\\mu)$ is always a convex function, and \n",
    "\n",
    "$$\n",
    "\\min -\\ell(\\lambda,\\mu)\\text{ subject to } 0\\preceq \\mu.\n",
    "$$\n",
    "\n",
    "is always a convex program.\n",
    "\n",
    "\n",
    "#### Theorem: Suppose $({\\bf x}^\\ast,\\mu^\\ast,\\lambda^\\ast)$ are such that $(\\mu^\\ast,\\lambda^\\ast)$ are a solution to the dual program and ${\\bf x}^\\ast$ is a solution to $\\min_{\\bf x} \\mathcal{L}({\\bf x},\\mu^\\ast,\\lambda^\\ast)$. Then (1) strong duality holds, (2) ${\\bf x}^\\ast$ is a solution to the primal problem, and (3) if all functions are also differentiable, $({\\bf x}^\\ast,\\mu^\\ast,\\lambda^\\ast)$ satisfy the KKT conditions.\n",
    "\n",
    "The power of this theorem is that, if the dual problem can be solved, then one immediately obtains a solution to the primal problem, and this is true for **any** optimization program (so in principle the primal problem need not be convex). On the other hand, this tell us that failure of strong duality means that we cannot hope to find a solution to the dual problem. \n",
    "\n",
    "#### Proof:\n",
    "\n",
    "We first show that $({\\bf x}^\\ast,\\mu^\\ast,\\lambda^\\ast)$ will always satisfy the primal feasibility, dual feasibility, and complementary slackness from the KKT conditions even if the functions are not necessarily differentiable.\n",
    "\n",
    "1. **Primal Feasibility Holds**: If any $g_i({\\bf x}^\\ast)\\not=0$, we could choose a $\\widetilde{\\lambda}_i$ so that $\\lambda_i^\\ast g_i({\\bf x}^\\ast)< \\widetilde{\\lambda}_i g_i({\\bf x}^\\ast)$ without changing any of the other $\\lambda_i^\\ast$'s or $\\mu_j^\\ast$'s. Thus, we would contradict optimality of $(\\lambda^\\ast,\\mu^\\ast)$. On the other hand, if any $h_j({\\bf x}^\\ast)>0$, we could pick $\\widetilde{\\mu}_j$ so that $\\mu_j^\\ast h_j({\\bf x}^\\ast)<\\widetilde{\\mu}_j h_j({\\bf x}^\\ast)$ without changing the other $\\lambda_i$'s or $\\mu_j$'s. This would also contradict optimality of $(\\lambda^\\ast,\\mu^\\ast)$.\n",
    "2. **Dual Feasibility Holds**: This holds by definition since $0\\preceq \\mu$ in the dual program.\n",
    "3. **Complementary Slackness Holds**: Suppose that $\\mu_j^\\ast h_j({\\bf x}^\\ast)\\not=0$ for some $j$. Because we have verified primal feasibility and dual feasibility, it must be the case that $\\mu_j^\\ast h_j({\\bf x^\\ast})\\leq 0$, so our assumption implies that $\\mu_j^\\ast h_j({\\bf x}^\\ast)<0$ and $h_j({\\bf x}^\\ast)<0$. But then setting $\\widetilde{\\mu}_j=0$ gives $\\mu_j^\\ast h_j({\\bf x}^\\ast)<\\widetilde{\\mu}_j h_j({\\bf x}^\\ast)=0$, contradicting optimality of $\\mu^\\ast$.\n",
    "\n",
    "Because of primal feasibility and complementary slackness, we have that $\\lambda_i^\\ast g_i({\\bf x}^\\ast)=0$ for all $i=1,\\ldots, n$, and $\\mu_j^\\ast h_j({\\bf x}^\\ast)=0$ for all $j=1,\\ldots, m$. Consequently,\n",
    "\n",
    "$$\n",
    "d^\\ast = \\min_{\\lambda, 0\\preceq\\mu} \\ell(\\lambda,\\mu)=\\mathcal{L}({\\bf x}^\\ast,\\lambda^\\ast,\\mu^\\ast)=f({\\bf x}^\\ast)+\\sum_{i=1}^n \\lambda_i g_i({\\bf x}^\\ast) + \\sum_{j=1}^m \\mu_jh_j({\\bf x}^\\ast)=f({\\bf x}^\\ast).\n",
    "$$\n",
    "\n",
    "This implies that $p^\\ast\\leq f({\\bf x}^\\ast)=d^\\ast$, and therefore weak duality implies $d^\\ast=p^\\ast$. Thus, strong duality holds, and since ${\\bf x}^\\ast$ is primal feasible and $f({\\bf x}^\\ast)=p^\\ast$, we conclude that ${\\bf x}^\\ast$ solves the primal problem.\n",
    "\n",
    "Finally, assuming differentiability of $f$, $g_i$'s, and $h_j$'s, the necessary conditions for optimality immediately imply that\n",
    "\n",
    "$$\n",
    "\\nabla_{\\bf x} \\mathcal{L}({\\bf x}^\\ast,\\lambda^\\ast,\\mu^\\ast) = \\nabla f({\\bf x}^\\ast)+\\sum_{i=1}^n\\lambda_i^\\ast \\nabla g_i({\\bf x}^\\ast)+\\sum_{j=1}^m\\mu_i^\\ast \\nabla h_j({\\bf x}^\\ast)={\\bf 0}.\n",
    "$$\n",
    "\n",
    "That is, **Stationarity holds**, and we see that all of the KKT conditions hold for $({\\bf x}^\\ast, \\lambda^\\ast,\\mu^\\ast)$. This completes the proof. $\\blacksquare$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duality and Convexity\n",
    "\n",
    "While the above theorem offers a sufficient condition, the following theory tells us that these conditions are also necessary when we have a sufficiently nice convex program.\n",
    "\n",
    "#### Theorem: If the primal program is a continuously differentiable convex program that satisfies Slater's condition, then strong duality holds and the KKT conditions are necessary and sufficient for optimality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duality and SVMs\n",
    "\n",
    "A dataset $\\{({\\bf x}^{(i)}, y^{(i)}\\}_{i=1}^N\\subset\\mathbb{R}^2\\times\\{-1,1\\}$ is called **linearly separable** if there is an $\\alpha\\in\\mathbb{R}^2$ and $\\alpha_0\\in\\mathbb{R}$ such that\n",
    "\n",
    "$$\n",
    "1 - y^{(i)}\\left(\\alpha^T {\\bf x}^{(i)}+\\alpha_0\\right)< 0\\text{ for all }i=1,\\ldots, N.\n",
    "$$\n",
    "\n",
    "Geometrically, this means that there is a line separating the data with labels $-1$ and the data with labels $+1$, and none of the data lies along this line. \n",
    "\n",
    "#### Theorem: The maximum margin problem is strictly feasible (i.e. Slater's condition holds) if and only if the labelled data is separable.\n",
    "\n",
    "So, if our data is linearly separable, the duality theory tells us we can instead attempt to solve the dual problem to margin maximization.\n",
    "\n",
    "Using the substitutions $\\alpha_1=a,\\alpha_2=b, \\alpha_0=c$, and using data of the for $\\{({\\bf x}^{(i)}, y^{(i)}\\}_{i=1}^N\\subset\\mathbb{R}^2\\times\\{-1,1\\}$, the training program for the separating line becomes\n",
    "\n",
    "$$\n",
    "\\min \\frac{1}{2}\\Vert\\alpha\\Vert^2\\text{ subject to } 1-y^{(i)}(\\alpha^T {\\bf x}^{(i)} +\\alpha_0)\\leq 0\n",
    "$$\n",
    "\n",
    "The Lagrangian for this program is\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\alpha,\\alpha_0,\\mu)= \\frac{1}{2}\\Vert\\alpha\\Vert^2 + \\sum_{i=1}^N\\mu_i\\left(1-y^{(i)}(\\alpha^T {\\bf x}^{(i)} +\\alpha_0)\\right).\n",
    "$$\n",
    "\n",
    "To compute $\\ell(\\mu)$, the necessary conditions for optimality of $\\mathcal{L}(\\alpha_0,\\alpha,\\mu)$ when $0\\preceq\\mu$ is fixed are seen to be\n",
    "\n",
    "$$\n",
    "{\\bf 0} = \\nabla_\\alpha \\mathcal{L}(\\alpha_0,\\alpha,\\mu)=\\alpha - \\sum_{i=1}^N \\mu_i y^{(i)}{\\bf x}^{(i)}\\:\\left(\\text{ or } \\alpha=\\sum_{i=1}^N \\mu_i y^{(i)}{\\bf x}^{(i)}\\right),\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "0 = \\frac{\\partial\\mathcal{L}}{\\partial\\alpha_0}(\\alpha_0,\\alpha,\\mu)=-\\sum_{i=1}^N\\mu_i y^{(i)}\\:\\left(\\text{ or }\\sum_{i=1}^N\\mu_i y^{(i)}=0\\right).\n",
    "$$\n",
    "\n",
    "Substituting in these expressions to $\\mathcal{L}$, we have that\n",
    "\n",
    "$$\n",
    "\\ell(\\mu) = \\frac{1}{2}\\left\\Vert\\sum_{i=1}^N \\mu_i y^{(i)}{\\bf x}^{(i)}\\right\\Vert^2 + \\sum_{i=1}^N\\mu_i - \\left(\\sum_{i=1}^N \\mu_i y^{(i)}{\\bf x}^{(i)}\\right)^T\\left(\\sum_{i=1}^N \\mu_iy^{(i)}{\\bf x}^{(i)}\\right)-\\alpha_0\\sum_{i=1}^N\\mu_iy^{(i)} = -\\frac{1}{2}\\left\\Vert\\sum_{i=1}^N \\mu_i y^{(i)}{\\bf x}^{(i)}\\right\\Vert^2 + \\sum_{i=1}^N\\mu_i.\n",
    "$$\n",
    "\n",
    "Setting $C\\in M_{N, N}$ to be $C=\\left(y^{(i)}y^{(j)}\\left({\\bf x}^{(i)}\\right)^T{\\bf x}^{(j)}\\right)$, we see that the dual program is\n",
    "\n",
    "$$\n",
    "\\max -\\frac{1}{2}\\mu^T C\\mu +{\\bf 1}^T\\mu\\text{ subject to }{\\bf y}^T\\mu=0,\\: 0\\preceq\\mu,\n",
    "$$\n",
    "\n",
    "which is equivalent to the convex program\n",
    "\n",
    "$$\n",
    "\\min \\frac{1}{2}\\mu^T C\\mu -{\\bf 1}^T\\mu\\text{ subject to }{\\bf y}^T\\mu=0,\\: 0\\preceq\\mu,\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Kernel Trick\n",
    "\n",
    "The form of the dual problem suggests that we can replace the $C$ matrix with $\\left(y^{(i)}y^{(j)} K({\\bf x}^{(i)},{\\bf x}^{(j)})\\right)$ where $K:\\mathbb{R}^d\\times\\mathbb{R}^d\\rightarrow\\mathbb{R}$ has the form\n",
    "\n",
    "$$\n",
    "K({\\bf a}, {\\bf b}) = \\sum \\varphi_k({\\bf a})\\varphi_k({\\bf b})\n",
    "$$\n",
    "\n",
    "for some $\\varphi_k:\\mathbb{R}^d\\rightarrow\\mathbb{R}$. The reason this works is because $K$ computes an inner product between the points\n",
    "\n",
    "$$\n",
    "\\varphi({\\bf a}) = \\begin{pmatrix}\\varphi_1({\\bf a})\\\\ \\varphi_2({\\bf a})\\\\ \\varphi_3({\\bf a})\\\\\\vdots\\end{pmatrix}\\text{ and }\\varphi({\\bf b}) = \\begin{pmatrix}\\varphi_1({\\bf b})\\\\ \\varphi_2({\\bf b})\\\\ \\varphi_3({\\bf b})\\\\\\vdots\\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "For example, if $\\sigma>0$, the **Gaussian Kernel**\n",
    "\n",
    "$$\n",
    "K_{\\text{exp},\\sigma}({\\bf a}, {\\bf b}) = e^{-\\Vert {\\bf a}-{\\bf b}\\Vert^2/\\sigma}\n",
    "$$\n",
    "\n",
    "can be shown to have this form using **Mercer's Theorem**. In this formulation, if $\\mu^\\ast$ solves the dual problem with $C = \\left(y^{(i)}y^{(j)} K({\\bf x}^{(i)},{\\bf x}^{(j)})\\right)$, then the decision boundary evaluation\n",
    "\n",
    "$$\n",
    "\\left(\\alpha^\\ast\\right)^T{\\bf x} = \\sum_{i=1}^N\\mu_i^\\ast y^{(i)}\\left({\\bf x}^{(i)}\\right)^T{\\bf x}\n",
    "$$\n",
    "\n",
    "from the usual SVM instead becomes\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^N\\mu_i^\\ast y^{(i)} K\\left({\\bf x}, {\\bf x}^{(i)}\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group Problems\n",
    "\n",
    "1. Compare and contrast SVM versus Logistic Regression.\n",
    "2. Suppose you have four classes that you want to separate by training several SVMs. What are two possible ways to do this?\n",
    "3. Write down a Phase I method for the primal maximum margin problem.\n",
    "4. For the primal problem, write out the search directions for the primal-dual algorithm.\n",
    "5. Suppose $\\mu^\\ast$ solves the dual problem for the SVM. How do you recover $\\alpha^\\ast$ and $\\alpha_0^\\ast$ for the separating line?\n",
    "6. Suppose $\\mu^\\ast$ solves the dual problem for the SVM, and $\\mu_i^\\ast=1$ for some $i$. What does this imply about ${\\bf x}^{(i)}$?\n",
    "7. For the dual problem, write out the search directions for the primal-dual algorithm.\n",
    "8. Show that, for $K:\\mathbb{R}^2\\times\\mathbb{R}^2\\rightarrow\\mathbb{R}$ defined by $K({\\bf x},{\\bf y}) = ({\\bf x}^T{\\bf y}+1)^2$, $K$ satisfies $K(x,y)=\\sum_{k=1}^6\\varphi_k({\\bf x})\\varphi_k({\\bf y})$ where $\\varphi({\\bf x}) = \\begin{pmatrix} x_1^2\\\\ \\sqrt{2}x_1x_2\\\\ x_2^2\\\\\\sqrt{2}x_1\\\\\\sqrt{2}x_2\\\\1\\end{pmatrix}$"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
