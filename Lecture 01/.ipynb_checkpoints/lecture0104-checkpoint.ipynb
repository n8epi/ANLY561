{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 1: *Review of Univariate Optimization*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: Preliminaries and Definitions\n",
    "We let $\\mathbb{R}$ denote the set of real numbers. Suppose $f:\\mathbb{R}\\rightarrow\\mathbb{R}$ is a real-valued function. An **optimization program** involves a search for the largest (or, smallest) value $f$ attains, as well as any possible points $x$ for which $f(x)$ is exactly this largest (or, smallest) value. Such an $f$ is often called an **objective function** or just an **objective**.\n",
    "\n",
    "To begin with, a **minimization program** over $\\mathbb{R}$ is written\n",
    "$$\n",
    "(P_\\min):\\:\\:\\min_{x\\in\\mathbb{R}}\\: f(x)\n",
    "$$\n",
    "where $f:\\mathbb{R}\\rightarrow\\mathbb{R}$ is a real-valued function. A point $x^\\ast\\in\\mathbb{R}$ is said to be a **solution** to (or, **minimizer**/**minimum** of) $(P_\\min)$ if $f(x^\\ast)\\leq f(x)$ for all $x\\in\\mathbb{R}$. \n",
    "\n",
    "A **maximization program** over $\\mathbb{R}$ is written\n",
    "$$\n",
    "(P_\\max):\\:\\:\\max_{x\\in\\mathbb{R}}\\: f(x).\n",
    "$$\n",
    "A point $x^\\ast\\in\\mathbb{R}$ is said to be a **solution** to (or, **maximizer**/**maximum** of) $(P_\\max)$ if $f(x)\\leq f(x^\\ast)$ for all $x\\in\\mathbb{R}$.\n",
    "\n",
    "Two optimization programs are said to be **equivalent** if a solution for one is always a solution for the other as well.\n",
    "\n",
    "## The Reflection Principle\n",
    "\n",
    "If $x^\\ast$ is a solution to $(P_\\max)$, then $x^\\ast$ is a solution to \n",
    "$$\n",
    "\\min_{x\\in\\mathbb{R}}\\: -f(x).\n",
    "$$\n",
    "Similarly, if $z_\\ast$ is a solution $(P_\\min)$, then $z_\\ast$ is a solution to\n",
    "$$\n",
    "\\max_{x\\in\\mathbb{R}}\\: -f(x).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Example 01: The reflection principle\n",
    "'''\n",
    "\n",
    "# Import numerical python and pyplot\n",
    "import numpy as np # Namespace is np\n",
    "import matplotlib.pyplot as plt # Namespace is plt\n",
    "\n",
    "def f(x):\n",
    "    '''\n",
    "    A simple quadratic polynomial\n",
    "    :param x: a numerical value or numpy array\n",
    "    :return: 1-x^2\n",
    "    '''\n",
    "    return 1 - x**2\n",
    "\n",
    "x = np.linspace(-2, 2, 100) # a uniform partition of [0, 1] consisting of 100 points\n",
    "g = lambda z: -f(z) # anonymous function composing f with negation\n",
    "\n",
    "plt.figure('The reflection principle')\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot([-2, 2], [0, 0], 'k--') # The dashed line is y=0\n",
    "plt.plot(x, f(x)) # f(x) works because of \"vectorization\"\n",
    "plt.axis([-2, 2, -4, 4])\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.title('Original function')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot([-2, 2], [0, 0], 'k--') # The dashed line is y=0\n",
    "plt.plot(x, g(x))\n",
    "plt.axis([-2, 2, -4, 4])\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('-f(x)')\n",
    "plt.title('Reflected function')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It follows from the reflection principle that any maximization program is equivalent to the minimization program involving the negated function. Thus, we need only consider minimization programs when we talk about optimization.\n",
    "\n",
    "A **minimum value** of $f:\\mathbb{R}\\rightarrow\\mathbb{R}$ is a value $p\\in\\mathbb{R}$ such that $p\\leq f(x)$ and if $y\\leq f(x)$ for all $x\\in\\mathbb{R}$, then $y\\leq p$. Similarly, a **maximum value** of $f$ is a value $q$ satisfying $f(x)\\leq q$ for all $x\\in\\mathbb{R}$ and if $f(x)\\leq y$ for all $x\\in\\mathbb{R}$, then $q\\leq y$.\n",
    "\n",
    "## Constrained Optimization\n",
    "The above optimization programs over all of $\\mathbb{R}$ are often called **unconstrained** optimization programs. If instead we are only interested in optimizing over a subset $X\\subset\\mathbb{R}$, we write the **constrained** optimization program as\n",
    "$$\n",
    "(P):\\:\\:\\min f(x)\\text{ subject to }x\\in X\n",
    "$$\n",
    "In this case, a **minimum value** is any $p$ satisfying $p\\leq f(x)$ for all $x\\in X$, and if $r\\leq f(x)$ for all $x\\in\\mathbb{R}$, then $r\\leq p$. A **solution**/**minimizer**/**minimum** is any $x^{(0)}\\in X$ such that $f(x^{(0)})\\leq f(x)$ for all $x\\in X$.\n",
    "\n",
    "Any point $x\\in X$ is called a **feasible point** or just **feasible**, and the set $X$ is often called the **feasible region**, **region of optimization**, or **set of feasible points**. If $x\\not\\in X$, then $x$ is **not feasible**. If $X$ contains no points (i.e. $X$ is the empty set, or $X=\\emptyset$), then the program $(P)$ is called **infeasible**.\n",
    "\n",
    "## Team Problems\n",
    "1. Write down a function which does not have a minimum value.\n",
    "2. Write down a function which has a minimum value, but which does not have a minimzer.\n",
    "3. Can a function ever have a minimizer, but fail to have a minimum value?\n",
    "4. Suppose $x^\\ast$ solves $\\min_{x\\in\\mathbb{R}} -f(x)$. What is the maximum value of $f$ over $\\mathbb{R}$?\n",
    "5. Explain why the minimum value of $f$ is unique if it exists; that is, if $p$ and $q$ are both minimum values of $f$, show that $p=q$. Answer: Since $p$ is a minimum value, then $p\\leq q$. Also, $q\\leq p$ since $q$ is minimum. By trichotomy, $p=q$.\n",
    "6. Explain why $\\min x^2$ subject to $x^2+2x+2\\leq 0$ is an infeasible program.\n",
    "7. Suppose $f, g:\\mathbb{R}\\rightarrow\\mathbb{R}$ and $p>-\\infty$ is the minimum value of $g$. Is $p$ the minimum value of $h=g\\circ f$ (i.e. $h(x)=g(f(x))$? \n",
    "8. A function $f:\\mathbb{R}\\rightarrow\\mathbb{R}$ is **monotone decreasing** if $f(x)>f(y)$ for all $x<y$. If $f$ is monotone decreasing, show that it cannot have a minimizer. Answer: Suppose $x^\\ast$ is a minimizer. Then $f(x^\\ast+1)<f(x^\\ast)$ since $x^\\ast < x^\\ast + 1$, so we have contradicted the fact that $x^\\ast$ is a solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Important considerations\n",
    "When approaching any optimization program, there are some basic questions that need to be answered.\n",
    "\n",
    "1. Does $(P_\\min)$ have a minimum value?\n",
    "2. Does $(P_\\min)$ have a solution?\n",
    "3. Does $(P_\\min)$ have a **unique** solution?\n",
    "4. When $(P_\\min)$ has a minimum value, how can we find an $\\widetilde{x}$ such that $f(\\widetilde{x})$ is close to the minimum value?\n",
    "5. When $(P_\\min)$ has a solution $x^\\ast$, how can we find an $\\widetilde{x}$ which is close to $x^\\ast$?\n",
    "\n",
    "Without imposing additional structure on $f$, the answers to these questions are generally \"no.\" In each of the following sections, we explore conditions on $f$ which allow us to know when the answers to the above questions are \"yes.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III: Existence of minimum values and minimizers\n",
    "\n",
    "If there is an $L\\in\\mathbb{R}$ such that $L\\leq f(x)$ for all $x\\in\\mathbb{R}$, then $f$ is said to be **bounded below**.\n",
    "\n",
    "### Theorem: If $f$ is bounded below, then $(P_\\min)$ has a minimum value.\n",
    "\n",
    "A function $f:\\mathbb{R}\\rightarrow\\mathbb{R}$ is **continuous** if $f(x)=\\lim_{n\\rightarrow\\infty} f(x_n)$ whenever $x=\\lim_{n\\rightarrow\\infty} x_n$, and where $\\{x_n\\}_{n=1}^\\infty$ is a real sequence.\n",
    "\n",
    "Given a set $X\\subset\\mathbb{R}$, a function $f:X\\rightarrow\\mathbb{R}$ is **continuous on $X$** if $f(x)=\\lim_{n\\rightarrow\\infty} f(x_n)$ whenever $\\lim_{n\\rightarrow\\infty} x_n=x$, where $\\{x_n\\}_{n=1}^\\infty\\subset X$ and $x\\in X$. That is, $\\{x_n\\}_{n=1}^\\infty$ is a sequence in $X$ that converges to a point in $X$.\n",
    "\n",
    "A set $X\\subset\\mathbb{R}$ is said to be **closed** if whenever $\\{x_n\\}_{n=1}^\\infty\\subset X$ (that is, $\\{x_n\\}_{n=1}^\\infty$ is a sequence in $X$), and $x=\\lim_{n\\rightarrow\\infty}x_n$, then $x\\in X$. That is, $X$ is closed with respect to convergent limits.\n",
    "\n",
    "A set $X\\subset\\mathbb{R}$ is said to be **bounded** if there is an $R>0$ with $X\\subset (-R, R)$. $X$ is said to be **compact** if $X$ is closed and bounded.\n",
    "\n",
    "In 1D, the simplest class of examples of compact sets are intervals of the form $[a, b]$, where $a,b\\in \\mathbb{R}$ and $a\\leq b$.\n",
    "\n",
    "\n",
    "### Theorem (Extreme Value Theorem): If $X$ is compact and $f:X\\rightarrow\\mathbb{R}$ is continuous on $X$, then $f$ has a minimizer $x^\\ast\\in X$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part IV: Uniqueness of Solutions and Convexity\n",
    "Uniqueness of solutions is generally contingent upon convexity of the optimization program. \n",
    "\n",
    "A set $X\\subset\\mathbb{R}$ is said to be **convex** if for any $a, b\\in X$ and any $t\\in[0,1]$, $(1-t)a + tb\\in X$. It turns out that all convex subsets of $\\mathbb{R}$ are of the form $(a, b)$, $(a, b]$, $[a, b)$, or $[a, b]$ where $a$ can be $-\\infty$ and $b$ can be $\\infty$.\n",
    "\n",
    "If $X$ is a convex set:\n",
    "\n",
    "1. $f:X\\rightarrow\\mathbb{R}$ is said to be **convex** on $X$ if for every $a, b\\in X$ and every $t\\in[0,1]$ we have that\n",
    "$$\n",
    "f((1-t)a + tb) \\leq (1-t)f(a) + t f(b).\n",
    "$$ \n",
    "2. $f:X\\rightarrow\\mathbb{R}$ is said to be **strictly convex** on $X$ if for every $a\\not= b\\in X$ and every $t\\in(0,1)$ we have that\n",
    "$$\n",
    "f((1-t)a + tb) < (1-t)f(a) + t f(b).\n",
    "$$ \n",
    "3. $f:X\\rightarrow\\mathbb{R}$ is said to be **strongly convex** on $X$ if it is twice differentiable on $\\mathbb{R}$ and there is a $c>0$ such that $f^{\\prime\\prime}(x)>c$ for all $x\\in X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Convexity Examples\n",
    "'''\n",
    "\n",
    "t = np.linspace(0, 1, 100)\n",
    "x = np.linspace(-10, 10, 1000)\n",
    "a = 3\n",
    "b = 8\n",
    "l = (1-t)*a + t*b\n",
    "\n",
    "plt.plot(x, np.abs(x))\n",
    "plt.plot(l, (1-t)*np.abs(a) + t*np.abs(b), 'k--')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.title('Convex, but not strictly convex')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(x, np.exp(x/10))\n",
    "plt.plot(l, (1-t)*np.exp(a/10) + t*np.exp(b/10), 'k--')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.title('Strictly convex, but not strongly convex')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(x, x**4)\n",
    "plt.plot(l, (1-t)*a**4 + t*b**4, 'k--')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.title('Strictly convex, but $f^{\\prime\\prime}(0)=0$')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(x, x**2)\n",
    "plt.plot(l, (1-t)*a**2 + t*b**2, 'k--')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.title('Strongly convex')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not too difficult to establish that strong convexity implies strict convexity implies convexity. With additional work, convexity can be shown to imply continuity (except possibly at endpoints).\n",
    "\n",
    "#### Theorem (Convex Functions are Continuous): If $X$ is convex and open, and $f:X\\rightarrow\\mathbb{R}$ is convex on $X$, then $f$ is continuous on $X$.\n",
    "\n",
    "If $f$ is convex, then $(P_\\min)$ is called a **convex program**. \n",
    "\n",
    "Now, **strict minimizer**/**unique minimizer** of $f$ on $X$ is a point $x^\\ast$ such that $f(x^\\ast)<f(x)$ for all $x\\in X\\setminus\\{x^\\ast\\}$. We say that $f\\in C^2(X)$ if $f\\in C^1(X)$ and $f^\\prime\\in C^1(X)$.\n",
    "\n",
    "#### Theorem (Fundamental Theorem of Convex Programming): If $X\\subset\\mathbb{R}$ is convex, compact, and $f:X\\rightarrow\\mathbb{R}$ is  convex on $X$, then the set of minimizers of $f$ on $X$ form a convex set. Moreover, if $f$ strictly convex on $X$, then $f$ has a unique minimizer on $X$.\n",
    "\n",
    "This is a very strong theoretical guarantee, but we need some tools for verifying convexity. Let $C^1(X)$ denote the set of all functions $f:X\\rightarrow\\mathbb{R}$ such that $f^\\prime(x)$ exists for all $x\\in X$, and $f^\\prime(x)$ is continuous on $X$. \n",
    "\n",
    "#### Theorem (First Order Conditions for Convexity): If $X\\subset\\mathbb{R}$ is convex, then $f\\in C^1(X)$ is convex if and only if $f(x)\\geq f(y) + f^\\prime(y)(x-y)$ for all $x,y\\in X$. If $f(x) > f(y) + f^\\prime(y)(x-y)$ for all $x,y\\in X$, then $f$ is strictly convex.\n",
    "\n",
    "The first order conditions are not always easy to verify, so we would also like second order conditions to make our lives easier. \n",
    "\n",
    "#### Theorem (Second Order Conditions for Convexity):  If $X\\subset\\mathbb{R}$ is convex, then $f\\in C^2(X)$ is convex if and only if $f^{\\prime\\prime}(x)\\geq 0$ for all $x\\in X$. If $f^{\\prime\\prime}(x)>0$ for all $x\\in X$, then $f$ is strictly convex.\n",
    "\n",
    "These conditions are quite useful in practice, but there are also several operations that preserve convexity.\n",
    "\n",
    "#### Theorem (Positive Weighted Sum of Convex is Convex): If $X\\subset\\mathbb{R}$ is convex, $f,g:X\\rightarrow\\mathbb{R}$ are convex on $X$, and $a, b\\geq 0$, then $h:X\\rightarrow\\mathbb{R}$ defined by $h(x) = af(x) + bg(x)$ for all $x\\in X$ is convex on $X$.\n",
    "\n",
    "#### Theorem (Pointwise Maximum of Convex is Convex): If $X\\subset\\mathbb{R}$ is convex and $f, g:X\\rightarrow\\mathbb{R}$ are convex on $X$, then $h:X\\rightarrow\\mathbb{R}$ defined by $h(x) = \\max(f(x), g(x))$ for all $x$ is also convex on $X$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: pointwise maximum of two functions\n",
    "\n",
    "t = np.linspace(-1, 1, 100)\n",
    "f = lambda x: (x-1)**2\n",
    "g = lambda x: np.exp(x)\n",
    "h = lambda x: max(f(x), g(x)) # The pointwise maximum of f and g\n",
    "\n",
    "h_vals = np.zeros(100)\n",
    "for i in range(100):\n",
    "    h_vals[i] = h(t[i]) \n",
    "    \n",
    "plt.figure('Pointwise Max Example')\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(t, f(t))\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(t, g(t))\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(t, h_vals)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A function $f:\\mathbb{R}\\rightarrow\\mathbb{R}$ is called **affine** if there are $a, b\\in\\mathbb{R}$ such that $f(x)=ax+b$ for all $x\\in\\mathbb{R}$.\n",
    "\n",
    "#### Theorem (Convexity Preservation under Affine Precomposition): Suppose $X\\subset\\mathbb{R}$ is convex, $f:X\\rightarrow\\mathbb{R}$ is convex on $X$, $a,b\\in\\mathbb{R}$, and set $Y = \\{y\\in\\mathbb{R}: ay+b\\in X\\}$. Then $Y$ is convex and $g:Y\\rightarrow\\mathbb{R}$ defined by $g(y) = f(ay+b)$ for all $y\\in Y$ is convex on $Y$.\n",
    "\n",
    "For this next theorem, we define the **image** of a function $f:X\\rightarrow\\mathbb{R}$ as the set \n",
    "$$\n",
    "f(X)=\\{y\\in\\mathbb{R}: f(x)=y\\text{ for some }x\\in X\\}.\n",
    "$$\n",
    "Note that if $X$ is convex and $f$ is convex over $X$, then $f(X)$ is also convex: if $p, q\\in f(X)$, there are $v, w\\in X$ with $f(v)=p, f(w)=q$. Let $t\\in[0,1]$ and set $r=(1-t)p + tq$. Since $r$ is between $p$ and $q$, there is $z$ between $v$ and $w$ such that $f(z)=r$ by the Intermediate Value Theorem, and hence $(1-t)p+tq\\in f(X)$ for all $t\\in[0,1]$.\n",
    "\n",
    "We also say that a function $f:X\\rightarrow\\mathbb{R}$ is **non-decreasing** or **order preserving** on $X$ if $x\\leq y$ implies $f(x)\\leq f(y)$ for all $x, y\\in X$.\n",
    "\n",
    "#### Theorem (Convexity Preservation under Convex Monotone Transformation): Suppose $X\\subset\\mathbb{R}$ is convex, $f:X\\rightarrow\\mathbb{R}$ is convex on $X$, and that $g:f(X)\\rightarrow \\mathbb{R}$ is convex and non-decreasing, then $g\\circ f: X\\rightarrow\\mathbb{R}$ is convex on $X$.\n",
    "\n",
    "## Team Questions\n",
    "\n",
    "1. Show that $f(x)=x\\arctan(x) - \\frac{1}{2}\\log(1+x^2)$ is strictly convex on $\\mathbb{R}$. \n",
    "2. Show that $f(x)=-\\log(-x)$ is strictly convex and order preserving on $(-\\infty,0)$. \n",
    "3. If $X$ is convex and $f_1, f_2, \\ldots, f_k:X\\rightarrow\\mathbb{R}$ are all convex, explain why $g:X\\rightarrow\\mathbb{R}$ defined by $g(x)=\\sum_{i=1}^k f_i(x)$ is also convex.  \n",
    "4. If $X$ is convex and $f_1, f_2, \\ldots, f_k:X\\rightarrow\\mathbb{R}$ are all convex, explain why $g:X\\rightarrow\\mathbb{R}$ defined by $g(x)=\\max_{i=1,\\ldots, k} f_i(x)$ is also convex. \n",
    "5. For $x_1,x_2,\\ldots,x_N\\in\\mathbb{R}$, show that\n",
    "$$\n",
    "\\max_{x\\in\\mathbb{R}}\\prod_{i=1}^N e^{-\\frac{1}{2}(x-x_i)^2}\n",
    "$$\n",
    "is equivalent to a convex optimization program.\n",
    "6. A function is **concave** on $\\mathbb{R}$ if $f((1-t)x+ty)\\geq (1-t)f(x)+tf(y)$ for all $x,y\\in\\mathbb{R}$ and all $t\\in[0,1]$. Explain why $f$ is concave if and only if $-f$ is convex. \n",
    "7. What is the geometric interpretation of the first order condition $f(x)\\geq f(y)+f^\\prime(y)(y-x)$? \n",
    "8. The **epigraph** of a function $f:\\mathbb{R}\\rightarrow\\mathbb{R}$ is the set defined by $\\text{epi}(f) = \\{(x,y)\\in\\mathbb{R}\\times\\mathbb{R}: f(x)\\leq y\\}$. Show that $f$ is convex if and only if $((1-\\alpha)x_0+\\alpha x_1, (1-\\alpha)y_0+\\alpha y_1)$ for all $(x_0, y_0), (x_1, y_1)\\in\\text{epi}(f)$ and all $\\alpha\\in[0,1]$ (in other words, $\\text{epi}(f)$ is a convex 2D set and contains all line segments connecting points inside of it). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part V: Algorithms for Minimization\n",
    "\n",
    "\n",
    "## Brute force search\n",
    "Theoretically, one could simply employ **brute force search** to minimize a function $f$ by evaluating $f(x)$ for each point in the feasible region. However, our feasible regions have infinitely many points to consider, so this approach is impractical.\n",
    "\n",
    "Recall that a function $f:X\\rightarrow \\mathbb{R}$ is **differentiable** at $x^{(0)}\\in X$ if the limit\n",
    "$$\n",
    "f^\\prime(x^{(0)})=\\lim_{A\\ni x\\rightarrow x^{(0)}} \\frac{f(x)-f(x^{(0)})}{x-x^{(0)}}\n",
    "$$\n",
    "exists. If $f$ is differentiable at $x$ for all $x$ in $X$, then we say that $f$ is **differentiable on** $X$. If $f$ is differentiable on $X$ and the derivative function $f^\\prime$ is continuous on $X$, we say that $f$ is **continuously differentiable** and write $f\\in C^1(X)$. Similarly, if $f^\\prime\\in C^1(X)$, we say that $f\\in C^2(X)$, and if $f^\\prime\\in C^2(X)$ then $f\\in C^3(X)$.\n",
    "\n",
    "The **interior** of a set $X\\subset\\mathbb{R}$, denoted $\\text{int}(X)$ is the largest open subset of $\\mathbb{R}$ in $X$. In particular, $x\\in \\text{int}(X)$ if and only if there is an $\\varepsilon>0$ such that $(x-\\varepsilon, x+\\varepsilon)\\subset X$.\n",
    "\n",
    "### Theorem (Necessary Conditions for Optimality): If $f:X\\rightarrow\\mathbb{R}$ is differentiable on $X$ and $x^\\ast\\in\\text{int}(X)$ is a minimizer of $f$, then $f^\\prime(x^\\ast)=0$.\n",
    "\n",
    "The necessary conditions for optimality are most useful when\n",
    "\n",
    "1. enough is known about $f$ to analytically find all solutions to $f^\\prime(x)=0$, and\n",
    "2. the solution set of $f^\\prime(x)=0$ is either small or easy to characterize.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Example 02: f(x)=(x-1)(x-2)(x-4)(x-8) = x^4 -15x^3  on [0, 6]\n",
    "'''\n",
    "\n",
    "def poly_deriv_coeffs(a):\n",
    "    '''\n",
    "    Computes the coefficients of the derivative of a poly from the coeffs of a poly\n",
    "    :param a: coefficients of a poly in decreasing order of associated degree\n",
    "    :return: coeffs of deriv in decreasing order of the degree\n",
    "    '''\n",
    "    b=[]\n",
    "    for i in range(len(a)-1):\n",
    "        b.append((len(a)-1-i)*a[i])\n",
    "    return b\n",
    "\n",
    "p = lambda x: (x-1) * (x-2) * (x-4) * (x-8)\n",
    "\n",
    "coeffs = np.poly([1, 2, 4, 8])\n",
    "dcoeffs = poly_deriv_coeffs(coeffs)\n",
    "roots = np.roots(dcoeffs) # numpy computes the zeros of the poly's derivative from the coeffs of the deriv\n",
    "\n",
    "feasible_solutions = roots[roots <= 6] # remove all roots above 6\n",
    "feasible_solutions = feasible_solutions[0 <= feasible_solutions] # remove all roots below 0\n",
    "feasible_solutions = np.append(feasible_solutions, [0, 6]) # add endpoints to check\n",
    "\n",
    "feas_vals = [p(t) for t in feasible_solutions]\n",
    "k = np.argmin(feas_vals)\n",
    "\n",
    "x_ast = feasible_solutions[k]\n",
    "p_min = feas_vals[k]\n",
    "\n",
    "print('p attains the minimum value %f at %f on [0, 6]' % (p_min, x_ast))\n",
    "\n",
    "s = np.linspace(0, 6, 100)\n",
    "p_graph = p(s)\n",
    "\n",
    "plt.plot([0, 6], [0, 0], 'k--')\n",
    "plt.plot(s, p_graph)\n",
    "plt.scatter([x_ast], [0])\n",
    "plt.scatter([x_ast], [p_min])\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.title('Brute force using necessary conditions')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the points for which $f^\\prime(x)=0$ are called **critical points**. There are several important types of critical points.\n",
    "\n",
    "1. $x$ is a **local minimizer** of $f:X\\rightarrow\\mathbb{R}$ if there is an $\\varepsilon>0$ such that $f(x)\\leq f(y)$ for all $y\\in(x-\\varepsilon, x+\\varepsilon)\\cap X$ (the **intersection** of the $\\varepsilon$-neighborhood around $x$ and $X$).\n",
    "2. $x$ is a **local maximizer** of $f:X\\rightarrow\\mathbb{R}$ if there is an $\\varepsilon>0$ such that $f(x)\\geq f(y)$ for all $y\\in(x-\\varepsilon, x+\\varepsilon)\\cap X$\n",
    "3. $x$ is a **global minimizer** of $f:X\\rightarrow\\mathbb{R}$ if $f(x)\\leq f(y)$ for all $y\\in X$. \n",
    "4. $x$ is a **global maximizer** of $f:X\\rightarrow\\mathbb{R}$ if $f(x)\\geq f(y)$ for all $y\\in X$. \n",
    "\n",
    "Note that a global minimizer in the interior of a set must also be a local minimizer. Thus, the second derivative test allows us to exclude all local maximizers from our search.\n",
    "\n",
    "### Theorem (Second Derivative Test): Let $f\\in C^2(X)$. If $x^\\ast\\in \\text{int}(X)$ is a global minimizer, then $f^{\\prime\\prime}(x^\\ast)\\geq0$.\n",
    "\n",
    "With a one more conditiodn on $f$, the necessary conditions also become sufficient conditions.\n",
    "\n",
    "### Theorem (Sufficient Conditions for Optimality): If $X\\subset\\mathbb{R}$ is a convex set, $f:X\\rightarrow\\mathbb{R}$ is convex and differentiable on $X$, and $x^\\ast\\in X$ satisfies $f^\\prime(x^\\ast)=0$, then $x^\\ast$ is a minimizer of $f$ on $X$.\n",
    "\n",
    "This gives us nice theoretical tools, and illustrates why convexity is so useful. On the other hand, solving $f^\\prime(x)=0$ may be exceedingly difficult, making brute force search on the critical points (and end points!) untenable for many applications.\n",
    "\n",
    "## Team Questions\n",
    "\n",
    "1. Find the minimizer of the function $f(x)=x^3-3x+1$ on the interval $[0, 2]$.\n",
    "2. Find the minimizer of the function $f(x)=\\frac{1}{x}e^x$ on the interval $(0,\\infty)$.\n",
    "3. Find the minimizer of the function $f(x)=\\log(1+e^{-x})+\\log(1+e^{x})$\n",
    "4. Find the minimizer of the function $f(x)=\\vert x-1\\vert + \\vert x-2\\vert + \\vert x-4\\vert$\n",
    "5. Find the minimizer of the function $f(x)=(x-1)^2+(x-2)^2+(x-4)^2$\n",
    "6. Find the minimizer of the function $f(x)=\\max(\\vert x-1\\vert, \\vert x-2\\vert, \\vert x-4\\vert)$\n",
    "7. Find the minimizer of the function $f(x)=x^4-4x+1$ on $[-3, -2]\\cup[3, 4]$\n",
    "8. Which of the above programs are convex?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "t1 = np.linspace(0, 2)\n",
    "f1 = lambda x: x**3 - 3*x +1\n",
    "\n",
    "t2 = np.linspace(0.1, 2)\n",
    "f2 = lambda x: np.exp(x)/x\n",
    "\n",
    "plt.figure('Graphs')\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(t1, f1(t1))\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(t2, f2(t2))\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Backtracking\n",
    "\n",
    "For problems that do not yield to brute force, we can often implement **iterative** methods that produce a sequence of points with smaller and smaller function values. Such methods generally only rely on local information (i.e. evaluations of the function and its derivative). We now construct a practical algorithm with the following properties:\n",
    "\n",
    "1. The algorithm can be used for any $f$ which is differentiable on $\\mathbb{R}$.\n",
    "2. The algorithm can be initialized with any point $x^{(0)}\\in\\mathbb{R}$ and produces a sequence of **iterates** $x^{(1)}, x^{(2)}, x^{(3)},\\ldots$ where the $(k+1)$th iterate $x^{(k+1)}$ only depends on $x^{(k)}$, $f(x^{(k)})$, $f^\\prime(x^{(k)})$, and two user-defined parameters $\\alpha, \\beta\\in (0,1)$\n",
    "3. The sequence of iterates satisfies $f(x^{(0)}) > f(x^{(1)}) > f(x^{(2)}) >\\cdots$\n",
    "\n",
    "To motivate the algorithm, assume that $f$ is differentiable on $\\mathbb{R}$, let $\\alpha, \\beta \\in (0, 1)$, $x\\in\\mathbb{R}$ with $f^\\prime(x)\\not=0$, and suppose that $\\Delta x$ has the opposite sign as $f^\\prime(x)$. If $f^\\prime(x)$ is positive, then note that $\\lim_{n\\rightarrow\\infty}\\beta^n=0$ and hence\n",
    "$$\n",
    "\\lim_{n\\rightarrow\\infty} \\frac{f(x + \\beta^n \\Delta x) - f(x)}{\\beta^n\\Delta x}=f^\\prime(x) > \\alpha f^\\prime(x).\n",
    "$$\n",
    "Consequently, there is an $N$ such that $n\\geq N$ implies\n",
    "$$\n",
    "\\frac{f(x + \\beta^n \\Delta x) - f(x)}{\\beta^n\\Delta x} > \\alpha f^\\prime(x).\n",
    "$$\n",
    "On the other hand, if $f^\\prime(x)<0$, then there is an $N$ such that $n\\geq N$ such that \n",
    "$$\n",
    "\\frac{f(x + \\beta^n \\Delta x) - f(x)}{\\beta^n\\Delta x} < \\alpha f^\\prime(x).\n",
    "$$\n",
    "In either case, it follows that there is an $n$ such that\n",
    "$$\n",
    "f(x + \\beta^n \\Delta x) - f(x) < \\alpha \\beta^n\\Delta x f^\\prime(x),\n",
    "$$\n",
    "and hence\n",
    "$$\n",
    "f(x + \\beta^n\\Delta x) < f(x) +\\alpha\\beta^n\\Delta x f^\\prime(x) < f(x).\n",
    "$$\n",
    "Thus, we simply need increase $n$ until this condition is satisfied to decrease the function.\n",
    "\n",
    "#### Theorem (Monotonicity of Backtracking): Suppose $f$ is differentiable on $\\mathbb{R}$ and $x^{(0)}\\in\\mathbb{R}$. Define the sequence $x^{(0)}, x^{(1)}, x^{(2)}, x^{(3)}, \\ldots$ by successively setting $x^{(k+1)}=x^{(k)} + \\beta^n\\Delta x^{(k)}$ where $n$ is the first $n\\geq 0$ such that $f(x^{(k)} + \\beta^n\\Delta x^{(k)})\\leq f(x^{(k)}) + \\alpha\\beta^n \\Delta x^{(k)} f^\\prime(x^{(k)})$, and where the increments $\\Delta x^{(1)}, \\Delta x^{(2)}, \\Delta x^{(3)},\\ldots$ which have the opposite signs as $f^\\prime(x^{(0)}),  f^\\prime(x^{(1)}), f^\\prime(x^{(2)}),\\ldots$. Then $f(x^{(0)}) > f(x^{(1)}) > f(x^{(2)}) > f(x^{(3)}) > \\cdots$. \n",
    "\n",
    "Our previous analysis gives us this nice theoretical guarantee, but it also offers quantitative estimates for the decrease from each $f(x^{(k)})$ to $f(x^{(k+1)})$. \n",
    "\n",
    "One immediate question presents itself: how do we choose $\\Delta x^{(k)}$, $\\alpha$, and $\\beta$? Generally we let $\\Delta x^{(k)}=-f^\\prime(x^{(k)})$, which is called **steepest descent**. The choices of $\\alpha$ and $\\beta$ are best explained by example.\n",
    "\n",
    "We now provide code for the backtracking algorithm, and we illustrate how it behaves in a simple scenario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import numerical python and pyplot\n",
    "import numpy as np # Namespace is np\n",
    "import matplotlib.pyplot as plt # Namespace is plt\n",
    "\n",
    "\n",
    "def backtracking1D(x0, dx, f, df0, alpha=0.2, beta=0.8, verbose=False):\n",
    "    '''\n",
    "    Backtracking for 1D functions with illustrations\n",
    "    :param x0: Previous point from backtracking $x^{(k)}$, or initial guess $x^{(0)}$\n",
    "    :param dx: Incremental factor for updating x0; $\\Delta x$\n",
    "    :param f: Objective function\n",
    "    :param df0: Derivative of f at x0 or $f^\\prime(x^{(0)})$\n",
    "    :param alpha: Sloping factor of stopping criterion\n",
    "    :param beta: \"Agressiveness\" parameter for backtracking steps\n",
    "    :param verbose: Boolean for providing plots to illustrate\n",
    "    :return: x1, the next iterate in backtracking, or $x^{(k+1)}$\n",
    "    '''\n",
    "    \n",
    "    print('In backtracking...')\n",
    "    \n",
    "    if verbose:\n",
    "        n=0\n",
    "        xs = [x0 + dx] * 3\n",
    "    \n",
    "    ######################################\n",
    "    # The core of the algorithm\n",
    "    ######################################\n",
    "    delta = alpha * dx * df0 # Just precomputing the alpha times increment times derivative factor\n",
    "    t = 1 # Initialize t=beta**0; beta**n in the loop\n",
    "    f0 = f(x0) # Evaluate for future use\n",
    "    x = x0 + dx # Initialize x_{0, inner}, $x = x^{(0)}+\\beta^0\\Delta x$\n",
    "    fx = f(x)\n",
    "    print(fx)\n",
    "    while (not np.isfinite(fx)) or fx > f0 + delta * t:\n",
    "        print(fx)\n",
    "        t = beta * t\n",
    "        x = x0 + t * dx\n",
    "        fx = f(x)\n",
    "    ###################################### \n",
    "    \n",
    "        if verbose:\n",
    "            n += 1\n",
    "            xs.append(x)\n",
    "            xs.pop(0)\n",
    "            \n",
    "    if verbose: \n",
    "        u = 1.1 * np.abs(xs[0] - x0)\n",
    "        l = 0.1 * np.abs(xs[0] - x0)\n",
    "        if dx < 0:\n",
    "            s = np.linspace(x0 - u, x0 + l, 100)\n",
    "            xi = [x0-u, x0]\n",
    "            fxi = [f(x0) - alpha*u*df0, f(x0)]\n",
    "        else:\n",
    "            s = np.linspace(x0 - l, x0 + u, 100)\n",
    "            xi = [x0, x0 + u]\n",
    "            fxi = [f(x0), f(x0) + alpha*u*df0]\n",
    "            \n",
    "        y = np.zeros(len(s))\n",
    "        for i in range(len(s)):\n",
    "            y[i] = f(s[i]) # Slow for vectorized functions\n",
    "            \n",
    "        plt.figure('Backtracking illustration')\n",
    "        arm, =plt.plot(xi, fxi, '--', label='Armijo Criterion')\n",
    "        fcn, =plt.plot(s, y, label='Objective Function')\n",
    "        plt.plot([s[0], s[-1]], [0, 0], 'k--')\n",
    "        pts =plt.scatter(xs, [0 for p in xs], label='Backtracking points for n=%d, %d, %d' % (n, n+1, n+2))\n",
    "        plt.scatter(xs, [f(p) for p in xs], label='Backtracking points for n=%d, %d, %d' % (n, n+1, n+2))\n",
    "        init =plt.scatter([x0, x0], [0, f(x0)], color='black', label='Initial point')\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('f(x)')\n",
    "        plt.legend(handles=[arm, fcn, pts, init])\n",
    "        plt.show()\n",
    "    \n",
    "    return x\n",
    "\n",
    "# We illustrate a few backtracking steps for  simple quadratic\n",
    "\n",
    "fun = lambda x: x**2\n",
    "dfun = lambda x: 2*x\n",
    "\n",
    "x0 = -3 # $x^{(0)}$\n",
    "dx = -dfun(x0) # $\\Delta x^{(0)} = -f^\\prime(x^{(0)})$\n",
    "\n",
    "alpha = 0.5\n",
    "beta = 0.1\n",
    "\n",
    "# First backtracking step\n",
    "#x1 = backtracking1D(x0, dx, fun, dfun(x0), alpha=alpha, beta=beta, verbose=True) # get $x^{(1)}$ from $x^{(0)}$\n",
    "\n",
    "x1 = backtracking1D(x0, -dfun(x0), fun, dfun(x0), alpha=alpha, beta=beta, verbose=True) # get $x^{(1)}$ from $x^{(0)}$\n",
    "\n",
    "# Second backtracking step\n",
    "x2 = backtracking1D(x1, -dfun(x1), fun, dfun(x1), alpha=alpha, beta=beta, verbose=True) # get $x^{(2)}$ from $x^{(1)}$\n",
    "\n",
    "# Third backtracking step\n",
    "x3 = backtracking1D(x2, -dfun(x2), fun, dfun(x2), alpha=alpha, beta=beta, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we see that the backtracking iterates $x^{(k)}$ rapidly tend towards $0$, and the **iterate values** $f(x^{(k)})$ also tend toward $f(0)=0$ very quickly. The speed of this convergence is often called the **convergence rate**. Now that we have an example algorithm, we can ask the following questions:\n",
    "\n",
    "1. Is there an algorithm which has a better convergence rate?\n",
    "2. Is there an algorithm which uses fewer evaluations of $f$ and $f^\\prime$?\n",
    "\n",
    "These questions seem very hard to answer, but it is possible to prove the following rate of convergence for the iterate values produced by backtracking.\n",
    "\n",
    "### Theorem: Suppose $f\\in C^2(\\mathbb{R})$ is convex, $x^\\ast$ minimizes $f$ on $\\mathbb{R}$, and there is an $M>0$ such that $\\vert f^{\\prime\\prime}(x)\\vert\\leq M$ for all $x\\in\\mathbb{R}$. If $x^{(0)}\\in\\mathbb{R}$ and $x^{(k)}$ are the iterates obtained from successively applying backtracking with steepest descent increment, then there is a constant $C>0$ such that\n",
    "$$\n",
    "f(x^{(k)})-f(x^\\ast) \\leq \\frac{C}{k}.\n",
    "$$\n",
    "\n",
    "So, we will say that backtracking has an $\\mathcal{O}(1/k)$ convergence rate. Now, is this rate optimal? Nesterov showed that a **first order method** (a method which only relies on the function and its derivative) cannot have a rate better than $C/k^2$, or $\\mathcal{O}(1/k^2)$. In many cases, the convergence rate for backtracking is nearly $1/k^2$, but it will do worse when a function has a very small derivative near the true solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Illustrating the slow rate of convergence for backtracking\n",
    "\n",
    "fun = lambda x: x**10\n",
    "dfun = lambda x: 10*(x**9)\n",
    "\n",
    "x = -0.5 # initial guess\n",
    "\n",
    "iterations = 100000\n",
    "alpha = 0.4\n",
    "beta = 0.8\n",
    "\n",
    "iterates = np.zeros(iterations+1)\n",
    "iterate_values = np.zeros(iterations+1)\n",
    "\n",
    "iterates[0] = x\n",
    "iterate_values[0] = fun(x)\n",
    "\n",
    "for i in range(iterations):\n",
    "    x = backtracking1D(x, -dfun(x), fun, dfun(x), alpha=alpha, beta=beta)\n",
    "    iterates[i+1] = x\n",
    "    iterate_values[i+1] = fun(x)\n",
    "    \n",
    "idx = np.array(list(range(iterations)))+1\n",
    "p1, = plt.semilogy(iterate_values, label='Function values')\n",
    "p2, = plt.semilogy(0.001/idx, label = '$1/k$ rate')\n",
    "p3, = plt.semilogy(1/(idx**2), label = '$1/k^2$ rate')\n",
    "plt.title('Convergence rate comparison')\n",
    "plt.legend(handles=[p1, p2, p3])\n",
    "plt.ylabel('Error = $| f(x^{(k)}) - 0 |$')\n",
    "plt.xlabel('Iterate index $k$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gap leads us to consider **accelerated** methods that may converge more rapidly. In particular, if we use data from two previous iterates, we can attain the optimal theoretical rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accelerated_backtracking1D(k, tk, x0, x1, dx, f, df, beta=0.8, verbose=False):\n",
    "    '''\n",
    "    Accelerated backtracking for 1D functions with illustrations\n",
    "    :param k: Index of the current accelerated backtracking iteration; k=1 for the first\n",
    "    :param tk: The t from the previous accelerated backtracking iteration; tk=1 for the first\n",
    "    :param x0: Next most recent point from accelerated backtracking\n",
    "    :param x1: Most recent point from accelerated backtracking; x1=x0 for the first iteration\n",
    "    :param dx: Incremental factor for updating x1\n",
    "    :param f: Objective function\n",
    "    :param df: Derivative function of f\n",
    "    :param beta: \"Agressiveness\" parameter for backtracking steps\n",
    "    :param verbose: Boolean for providing plots to illustrate\n",
    "    :return: x, t the next iterate and initial t in accelerated backtracking\n",
    "    '''\n",
    "    \n",
    "    y = x1 + (k-1)*(x1 - x0)/(k+2) # Base point for accelerated backtracking\n",
    "    \n",
    "    if verbose:\n",
    "        n=0\n",
    "        xs = [y + tk*dx] * 3\n",
    "    \n",
    "    t = tk # Initialize t from the last iteration; t_0=1\n",
    "    x = y + t*dx\n",
    "    fx = f(x)\n",
    "    fy = f(y)\n",
    "    dfy = df(y)\n",
    "    delta = dfy * dx\n",
    "\n",
    "    \n",
    "    while (not np.isfinite(fx)) or fy + delta*t + t*dx**2/2 < fx:\n",
    "        t = beta * t\n",
    "        x = y + t*dx\n",
    "        fx = f(x)\n",
    "    \n",
    "        if verbose:\n",
    "            n += 1\n",
    "            xs.append(x)\n",
    "            xs.pop(0)\n",
    "            \n",
    "    if verbose: \n",
    "        u = 1.1 * np.abs(xs[0] - y)\n",
    "        l = 0.1 * np.abs(xs[0] - y)\n",
    "        if dx < 0:\n",
    "            s = np.linspace(y - u, y + l, 100)\n",
    "            xi = np.linspace(y-u, y, 100)\n",
    "        else:\n",
    "            s = np.linspace(y - l, y + u, 100)\n",
    "            xi = np.linspace(y, y + u, 100)\n",
    "        dxi = xi-y\n",
    "        fxi = fy + dfy*dxi + dxi*dx/2\n",
    "            \n",
    "        z = np.zeros(len(s))\n",
    "        for i in range(len(s)):\n",
    "            z[i] = f(s[i]) # Slow for vectorized functions\n",
    "            \n",
    "        plt.figure('Accelerated Backtracking illustration')\n",
    "        plt.plot([s[0], s[-1]], [0, 0], 'k--')\n",
    "        arm, =plt.plot(xi, fxi, '--', label='Stopping Criterion')\n",
    "        fcn, =plt.plot(s, z, label='Objective Function')\n",
    "        pts =plt.scatter(xs, [0 for p in xs], label='Backtracking points for n=%d, %d, %d' % (n, n+1, n+2))\n",
    "        plt.scatter(xs, [f(p) for p in xs], label='Backtracking points for n=%d, %d, %d' % (n, n+1, n+2))\n",
    "        init =plt.scatter([y], [fy], label='Initial point', color='black')\n",
    "        plt.legend(handles=[arm, fcn, pts, init])\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('f(x)')\n",
    "        plt.show()\n",
    "    \n",
    "    return x, t\n",
    "\n",
    "fun = lambda x: x**2\n",
    "dfun = lambda x: 2*x\n",
    "\n",
    "x0 = -3\n",
    "x1 = backtracking1D(x0, -dfun(x0), fun, dfun(x0))\n",
    "dx = -dfun(x1)\n",
    "t0 = 1\n",
    "beta = 0.8\n",
    "\n",
    "x2, t1 = accelerated_backtracking1D(1, t0, x0, x1, dx, fun, dfun, beta=beta, verbose=True)\n",
    "x3, t2 = accelerated_backtracking1D(2, t1, x1, x2, -dfun(x2), fun, dfun, beta=beta, verbose=True)\n",
    "x4, t3 = accelerated_backtracking1D(3, t2, x2, x3, -dfun(x3), fun, dfun, beta=beta, verbose=True)\n",
    "x5, t4 = accelerated_backtracking1D(4, t3, x3, x4, -dfun(x3), fun, dfun, beta=beta, verbose=True)\n",
    "x6, t5 = accelerated_backtracking1D(5, t4, x4, x5, -dfun(x3), fun, dfun, beta=beta, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Illustrating the slow rate of convergence for backtracking\n",
    "\n",
    "fun = lambda x: x**10\n",
    "dfun = lambda x: 10*(x**9)\n",
    "\n",
    "x = -0.5 # initial guess\n",
    "\n",
    "iterations = 100000\n",
    "alpha = 0.4\n",
    "beta = 0.8\n",
    "\n",
    "iterates = np.zeros(iterations)\n",
    "iterate_values = np.zeros(iterations)\n",
    "\n",
    "iterates[0] = x\n",
    "iterates[1] = x\n",
    "iterate_values[0] = fun(x)\n",
    "iterate_values[1] = fun(x)\n",
    "\n",
    "t = 1\n",
    "\n",
    "for i in range(2, iterations):\n",
    "    x, t = accelerated_backtracking1D(i+1, t, iterates[i-2], iterates[i-1], -dfun(iterates[i-1]), fun, dfun, beta=beta)\n",
    "    iterates[i] = x\n",
    "    iterate_values[i] = fun(x)\n",
    "    \n",
    "idx = np.array(list(range(iterations)))+1\n",
    "p1, = plt.semilogy(iterate_values, label='Function values')\n",
    "p2, = plt.semilogy(0.0000001/idx, label = '$1/k$ rate')\n",
    "p3, = plt.semilogy(0.0001/(idx**2), label = '$1/k^2$ rate')\n",
    "plt.title('Accelerated convergence rate comparison')\n",
    "plt.legend(handles=[p1, p2, p3])\n",
    "plt.ylabel('Error = $| f(x^{(k)}) - 0 |$')\n",
    "plt.xlabel('Iterate index $k$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that acceleration manages to compensate for small derivatives. In particular, we see that accelerated steepest descent has a rate better than $\\mathcal{O}(1/k^2)$ *in this particular case*. The theory also shows that accelerated backtracking achieves the optimal rate.\n",
    "\n",
    "### Theorem: Suppose $f\\in C^2(\\mathbb{R})$ is convex, $x^\\ast$ minimizes $f$ over $\\mathbb{R}$, and that there is an $M>0$ such that $\\vert f^{\\prime\\prime}(x)\\vert\\leq M$ for all $x\\in\\mathbb{R}$. Then, for the sequence $x^{(1)}, x^{(2)}, x^{(3)},\\ldots$ produced by accelerated backtracking, there is a constant $C>0$ such that\n",
    "$$\n",
    "f(x^{(k)})-f(x^\\ast) \\leq \\frac{C}{k^2}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part VI: Algorithmic Solutions\n",
    "\n",
    "What if the value of the function is less important than convergence to a minimizer? In this case, methods like **Fibonnaci search** and **golden section search** are able to provide nearly optimal approximations to solutions given a fixed number of function evaluations. We will not consider these algorithms, and instead we will focus on techniques that leverage backtracking.\n",
    "\n",
    "## Steepest descent with constant step size\n",
    "\n",
    "Instead of employing backtracking, we can simply choose a parameter $\\tau\\in (0,1)$ to produce iterates of the form\n",
    "$$\n",
    "x^{(k+1)}=x^{(k)} - \\tau f(x^{(k)}).\n",
    "$$\n",
    "This is called **damped steepest descent**, or steepest descent with constant step size. While it may not be the most efficient procedure, it can be analyzed a little more easily.\n",
    "\n",
    "### Theorem: Suppose $f\\in C^2(\\mathbb{R})$ and there is an $M>0$ and a $c>0$ such that $c<f^{\\prime\\prime}(x)<M$ for all $x\\in\\mathbb{R}$. Then there is a $\\gamma\\in(0,1)$ such that the sequence $x^{(k+1)} = x^{(k)} - \\frac{1}{M}f^\\prime(x^{(k)})$ satisfies $\\vert x^{(k+1)}-x^\\ast\\vert \\leq \\gamma\\vert x^{(k)}-x^\\ast\\vert$ for all $k$ given any initial $x^{(0)}$.\n",
    "\n",
    "The proof uses the Mean Value Theorem:\n",
    "\n",
    "$$\n",
    "x^\\ast - x^{(k+1)} = x^\\ast - x^{(k)} + \\frac{1}{M} f^\\prime(x^{(k)})=x^\\ast - x^{(k)} + \\frac{1}{M} f^{\\prime\\prime}(\\xi)(x^{(k)}-x^\\ast) = \\left(1 - \\frac{1}{M} f^{\\prime\\prime}(\\xi)\\right)(x^\\ast - x^{(k)})\n",
    "$$\n",
    "for some $\\xi$ between $x^{(k)}$ and $x^\\ast$, and hence\n",
    "$$\n",
    "\\vert x^\\ast - x^{(k+1)}\\vert = \\left\\vert 1-\\frac{1}{M} f^{\\prime\\prime}(\\xi)\\right\\vert \\vert x^\\ast - x^{(k)}\\vert.\n",
    "$$\n",
    "The inequality $c< f^{\\prime\\prime}(\\xi) < M$ implies $\\frac{c}{M}< \\frac{f^{\\prime\\prime}(\\xi)}{M} < 1$, and hence $0<1-\\frac{f^{\\prime\\prime}(\\xi)}{M}< 1- \\frac{c}{M}<1$. We conclude that the theorem holds with $\\gamma=1-\\frac{c}{M}$.\n",
    "\n",
    "We call the quantity $\\vert x^{(k)}-x^\\ast\\vert$ the **error** of the approximation $x^{(k)}$ to $x^\\ast$. The type of convergence discussed in the previous theorem is called **linear convergence** of the error, though it is also sometimes called **exponential convergence** since it implies that the error decays exponentially:\n",
    "$$\n",
    "\\vert x^{(k)}-x^\\ast\\vert \\leq \\gamma^k\\vert x^{(0)}-x^\\ast\\vert.\n",
    "$$\n",
    "\n",
    "\n",
    "## Newton's method\n",
    "\n",
    "Newton's method is a way to get even faster convergence to solutions, but it requires evaluation of $f^{\\prime\\prime}$ at each step. The Newton iterates are defined by\n",
    "$$\n",
    "x^{(k+1)} = x^{(k)} - \\frac{f^\\prime(x^{(k)})}{f^{\\prime\\prime}(x^{(k)})}\n",
    "$$\n",
    "We let $C^3(\\mathbb{R})$ denote the space of functions over $\\mathbb{R}$ with three continuous derivatives.\n",
    "\n",
    "### Theorem (Quadratic Convergence of Newton's Method): Suppose $f\\in C^3(\\mathbb{R})$, $f^\\prime(x^\\ast)=0$, there is a constant $c>0$ such that $f^{\\prime\\prime}(x^\\ast)\\geq c$, and there is a constant $K>0$ such that $\\vert f^{\\prime\\prime\\prime}(x)\\vert \\leq K$ for all $x\\in\\mathbb{R}$. If $x^{(0)}$ satisfies $\\vert x^{(0)}-x^\\ast\\vert\\leq \\frac{2c}{3k}$, then the Newton iterates initialized with $x^{(0)}$ satisfy $\\vert x^{(k)}-x^\\ast\\vert\\leq \\frac{2c}{3K}$ and $\\vert x^{(k+1)} - x^\\ast\\vert \\leq \\frac{3K}{2c} \\vert x^{(k)}-x^\\ast\\vert^2$ for all $k\\geq 0$. \n",
    "\n",
    "The **quadratic convergence** here is also known as **doubly exponential convergence** since it implies \n",
    "$$\n",
    "\\vert x^{(k)}-x^\\ast\\vert \\leq \\gamma^{2^k-1}\\vert x^{(0)}-x^\\ast\\vert\n",
    "$$\n",
    "for some $\\gamma\\in(0,1)$. However, convergence in this theorem is contingent on the fact that $\\vert x^{(0)}-x^\\ast\\vert < \\frac{2c}{3K}$. It turns out that Newton's method may produce an unbounded sequence of iterates. On the other hand, we can always feed the $\\Delta x$ from Newton's method to backtracking to stabilize Newton's method. \n",
    "\n",
    "The following plots illustrate convergence rates for iterates and function values for these procedures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.log(1 - 9*np.log(10)/np.log(9/10))/np.log(2)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Example 03: f(x) = x*arctan(x) - log(1+x^2)/2, f'(x)=arctan(x), f''(x)=1/(1+x^2)\n",
    "'''\n",
    "\n",
    "f = lambda x: x * np.arctan(x) - np.log(1+x**2)/2 # minimum value is 0 at x=0\n",
    "df = lambda x: np.arctan(x)\n",
    "d2f = lambda x: 1/(1+x**2) # Note that M=1, but strong convexity does not hold\n",
    "\n",
    "iter = 30 # 30 iterations of each\n",
    "x0 = 0.5\n",
    "\n",
    "x_sd = [x0]\n",
    "f_sd = [f(x0)]\n",
    "x = x0\n",
    "for i in range(iter):\n",
    "    x = x - df(x)/2 # Using the constant stepsize 2 > 1\n",
    "    x_sd.append(x)\n",
    "    f_sd.append(f(x))\n",
    "    \n",
    "x_nm = [x0]\n",
    "f_nm = [f(x0)]\n",
    "x = x0\n",
    "for i in range(iter):\n",
    "    x = x - df(x)/d2f(x) # Using the constant stepsize 2 > 1\n",
    "    x_nm.append(x)\n",
    "    f_nm.append(f(x))\n",
    "    \n",
    "# Compare convergence of function values with semilog plot\n",
    "sd, =plt.semilogy(f_sd, label='Steepest descent')\n",
    "nm, =plt.semilogy(f_nm, label='Newton\\'s method')\n",
    "plt.xlabel('Iteration Index')\n",
    "plt.ylabel('Iterate Value Error')\n",
    "plt.legend(handles=[sd, nm])\n",
    "plt.title('Semilog plot of function values')\n",
    "plt.show()\n",
    "\n",
    "# Compare convergece of iterates to the minimizer\n",
    "sd, =plt.semilogy(np.abs(x_sd), label='Steepest descent')\n",
    "nm, =plt.semilogy(np.abs(x_nm), label='Newton\\'s method')\n",
    "plt.ylabel('Iterate Error')\n",
    "plt.xlabel('Iteration Index')\n",
    "plt.legend(handles=[sd, nm])\n",
    "plt.title('Semilog plot of iterate error')\n",
    "plt.show()\n",
    "\n",
    "# Let's finish with a comparison with backtracking and accelerated backtracking\n",
    "\n",
    "x_sd_bt = [x0]\n",
    "f_sd_bt = [f(x0)]\n",
    "x = x0\n",
    "for i in range(iter):\n",
    "    x = backtracking1D(x, -df(x), f, df(x))\n",
    "    x_sd_bt.append(x)\n",
    "    f_sd_bt.append(f(x))\n",
    "\n",
    "x_nm_bt = [x0]\n",
    "f_nm_bt = [f(x0)]\n",
    "x = x0\n",
    "for i in range(iter):\n",
    "    x = backtracking1D(x, -df(x)/d2f(x), f, df(x))\n",
    "    x_nm_bt.append(x)\n",
    "    f_nm_bt.append(f(x))\n",
    "    \n",
    "x_sd_abt = [x0]\n",
    "f_sd_abt = [f(x0)]\n",
    "x = backtracking1D(x0, -df(x0), f, df(x0))\n",
    "x_sd_abt.append(x)\n",
    "f_sd_abt.append(f(x))\n",
    "t = 1\n",
    "for i in range(2,iter):\n",
    "    x, t = accelerated_backtracking1D(i+1, t, x_sd_abt[i-2], x_sd_abt[i-1], -df(x), f, df)\n",
    "    x_sd_abt.append(x)\n",
    "    f_sd_abt.append(f(x))\n",
    "\n",
    "x_nm_abt = [x0]\n",
    "f_nm_abt = [f(x0)]\n",
    "x = backtracking1D(x0, -df(x0)/d2f(x0), f, df(x0))\n",
    "x_nm_abt.append(x)\n",
    "f_nm_abt.append(f(x))\n",
    "t = 1\n",
    "for i in range(2, iter):\n",
    "    x, t = accelerated_backtracking1D(i+1, t, x_nm_abt[i-2], x_nm_abt[i-1], -df(x)/d2f(x), f, df)\n",
    "    x_nm_abt.append(x)\n",
    "    f_nm_abt.append(f(x))\n",
    "\n",
    "# Compare convergence of function values with semilog plot\n",
    "sd, =plt.semilogy(f_sd, label='Steepest descent')\n",
    "nm, =plt.semilogy(f_nm, label='Newton\\'s method')\n",
    "sd_bt, = plt.semilogy(f_sd_bt, label='SD Backtracking')\n",
    "nm_bt, = plt.semilogy(f_nm_bt, label='NM Backtracking')\n",
    "sd_abt, = plt.semilogy(f_sd_abt, label='SD Backtracking+')\n",
    "nm_abt, = plt.semilogy(f_nm_abt, label='NM Backtracking+')\n",
    "plt.xlabel('Iteration Index')\n",
    "plt.ylabel('Iterate Value Error')\n",
    "plt.legend(handles=[sd, nm, sd_bt, nm_bt, sd_abt, nm_abt])\n",
    "plt.title('Semilog plot of function values')\n",
    "plt.show()\n",
    "\n",
    "# Compare convergece of iterates to the minimizer\n",
    "sd, =plt.semilogy(np.abs(x_sd), label='Steepest descent')\n",
    "nm, =plt.semilogy(np.abs(x_nm), label='Newton\\'s method')\n",
    "sd_bt, = plt.semilogy(np.abs(x_sd_bt), label='SD Backtracking')\n",
    "nm_bt, = plt.semilogy(np.abs(x_nm_bt), label='NM Backtracking')\n",
    "sd_abt, = plt.semilogy(np.abs(x_sd_abt), label='SD Backtracking+')\n",
    "nm_abt, = plt.semilogy(np.abs(x_nm_abt), label='NM Backtracking+')\n",
    "plt.xlabel('Iteration Index')\n",
    "plt.ylabel('Iterate Error')\n",
    "plt.legend(handles=[sd, nm, sd_bt, nm_bt, sd_abt, nm_abt])\n",
    "plt.title('Semilog plot of iterate error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Problems\n",
    "\n",
    "1. Write down a function $f\\in C^1(\\mathbb{R})$ and an initial point $x^{(0)}$ such that backtracking with steepest descent does not produce a sequence which converges to the *global minimizer* of $f$ over $\\mathbb{R}$.\n",
    "2. Write down a function $f\\in C^1(\\mathbb{R})$ and an initial point $x^{(0)}$ such that backtracking with steepest descent does not produce a sequence which converges to a *local minimizer* of $f$ over $\\mathbb{R}$.\n",
    "3. Suppose you code up a function ``fun`` and its derivative ``dfun`` in python, and you observe that backtracking at a particular $x^{(0)}$ produces the iterates $x^{(1)}=x^{(0)}$, $x^{(2)}=x^{(0)}$, and so forth. That is, backtracking does not move from $x^{(0)}$. What are two possible reasons for this?\n",
    "4. Can backtracking with steepest descent ever converge more rapidly than accelerated backtracking with steepest descent?\n",
    "5. Does accelerated backtracking produce a sequence of iterates for which the iterate values are monotone decreasing?\n",
    "6. If an iterative method converges linearly, what should a semilog plot of the error as a function of the iteration index look like? What about if the method converges quadratically?\n",
    "7. In the above plots, why does backtracking with steepest descent appear to converge quadratically?\n",
    "8. In the above example, why does simple backtracking have a faster convergence rate than accelerated backtracking?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part VII: Constrained Univariate Optimization\n",
    "\n",
    "All of the numerical procedures we have considered so far involve the numerical minimization over $\\mathbb{R}$. If we are instead optimizing over $[a, b]$ for some $a, b\\in\\mathbb{R}$ with $a<b$, then we need to ensure that our iterative methods always return a new point in $[a,b]$. Clearly, backtracking may be modified to be careful of such constraints, but the **log barrier method** also provides a way to carry out optimization in the constrained setting.\n",
    "\n",
    "Instead of solving\n",
    "$$\n",
    "\\min f(x)\\text{ subject to }x\\in[a,b]\n",
    "$$\n",
    "we solve a sequence of programs\n",
    "$$\n",
    "\\min f(x)-\\frac{1}{t}\\log(x-a)-\\frac{1}{t}\\log(b-x)\n",
    "$$\n",
    "where $t\\rightarrow\\infty$. The benefit here is that these functions produce NaNs if $x\\leq a$ or $x\\geq b$, which we can catch in the backtracking loop using the ``not np.isfinite(fx)`` conditional. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lb1D(x, a, b):\n",
    "    '''\n",
    "    Log barrier value of x between a and b\n",
    "    :param x: x between a and b\n",
    "    :param a: lower endpoint\n",
    "    :param b: upper endpoint\n",
    "    :return: evaluation of the log barrier function\n",
    "    '''\n",
    "    return -np.log(x-a)-np.log(b-x)\n",
    "\n",
    "def dlb1D(x, a, b):\n",
    "    '''\n",
    "    Log barrier derivative at x between a and b\n",
    "    :param x: x between a and b\n",
    "    :param a: lower endpoint\n",
    "    :param b: upper endpoint\n",
    "    :return: evaluation of the log barrier derivative\n",
    "    '''\n",
    "    return 1/(b-x) - 1/(x-a)\n",
    "\n",
    "def d2lb1D(x, a, b):\n",
    "    '''\n",
    "    Log barrier 2nd derivative x between a and b\n",
    "    :param x: x between a and b\n",
    "    :param a: lower endpoint\n",
    "    :param b: upper endpoint\n",
    "    :return: evaluation of the log barrier 2nd derivative\n",
    "    '''\n",
    "    return 1/((b-x)**2) + 1/((x-a)**2)\n",
    "\n",
    "a=0\n",
    "b=1\n",
    "x = np.linspace(a+1e-6, b-1e-6, 1000)\n",
    "lb = lambda z: lb1D(z, a=0, b=1)\n",
    "y = lb(x)\n",
    "\n",
    "plt.figure('Log Barrier Function')\n",
    "plt.plot(x, lb(x))\n",
    "plt.plot(x, lb(x)/2)\n",
    "plt.plot(x, lb(x)/4)\n",
    "plt.plot(x, lb(x)/8)\n",
    "plt.plot(x, lb(x)/16)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('Barrier Value')\n",
    "plt.title('The log barrier function as t approaches $\\infty$')\n",
    "plt.show()\n",
    "\n",
    "def log_barrier_opt_1D(a, b, x0, f, df, d2f=None, al=0.2, be=0.8, M=10, init_iter=5, out_iter=25, in_iter=15, verbose=False):\n",
    "    '''\n",
    "    Perform optimization of f using the log barrier method in 1D\n",
    "    :param a: lower bound of feasible region\n",
    "    :param b: upper bound of feasible region\n",
    "    :param x0: inital guess -- must satisfy a < x0 < b or this breaks\n",
    "    :param f: objective function\n",
    "    :param df: derivative of objective function\n",
    "    :param d2f: optional second derivative, invokes Newton steps\n",
    "    :param al: alpha for the backtracking calls\n",
    "    :param be: beta for the backtracking calls\n",
    "    :param M: increase factor for t\n",
    "    :param init_iter: number of initial backtracking calls\n",
    "    :param out_iter: number of outer iterations to perform\n",
    "    :param in_iter: number of inner iterations to perform\n",
    "    :param verbose: True generates illustrative plots\n",
    "    '''\n",
    "    \n",
    "    # First, approximate the solution with t=1\n",
    "    x = x0\n",
    "    if verbose:\n",
    "        pts = [x0]\n",
    "    \n",
    "    for i in range(init_iter):\n",
    "        flb = lambda z: f(z) + lb1D(z, a, b)\n",
    "        dflb0 = df(x) + dlb1D(x, a, b)\n",
    "        dx = -dflb0\n",
    "        if d2f is not None:\n",
    "            dx = dx / (d2f(x) + d2lb1D(x, a, b))\n",
    "        x = backtracking1D(x, dx, flb, dflb0, alpha=al, beta=be)\n",
    "        if verbose:\n",
    "            pts.append(x)\n",
    "            \n",
    "    if verbose:\n",
    "        s = np.linspace(a+1e-6, b-1e-6, 100)\n",
    "        y = np.zeros(100)\n",
    "        q = np.zeros(len(pts))\n",
    "        for i in range(100):\n",
    "            y[i] = flb(s[i])\n",
    "        for i in range(len(pts)):\n",
    "            q[i] = flb(pts[i])\n",
    "        \n",
    "        fl = min(np.min(q), 0)\n",
    "        fu = max(np.max(q), 0)\n",
    "            \n",
    "        interval_length = np.max(pts) - np.min(pts)\n",
    "        range_length = fu - fl\n",
    "            \n",
    "        l = np.min(pts) - 0.1*interval_length\n",
    "        u = np.max(pts) + 0.1*interval_length\n",
    "        fl = np.min(q) - 0.1*range_length\n",
    "        fu = np.max(q) + 0.1*range_length\n",
    "        \n",
    "        plt.plot([s[0], s[-1]], [0, 0], 'k--')\n",
    "        obj, =plt.plot(s, y, label='Objective plus barrier')\n",
    "        bt =plt.scatter(pts, np.zeros(len(pts)), label='Backtracking')\n",
    "        vals =plt.scatter(pts, q, label='Values')\n",
    "        init =plt.scatter([pts[-1]], 0, label='Initial center')\n",
    "        plt.axis([l, u, min(fl,0), max(fu,0)])\n",
    "        plt.legend(handles=[obj, bt, vals, init])\n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('f(x) plus barrier')\n",
    "        plt.title('Initial centering steps')\n",
    "        plt.show()\n",
    "    \n",
    "    # Now begin the outer iterations\n",
    "    t=1\n",
    "    for i in range(out_iter):\n",
    "        t = M * t\n",
    "        if verbose:\n",
    "            pts = [x]\n",
    "        for j in range(in_iter):\n",
    "            flb = lambda z: f(z) + lb1D(z, a, b)/t\n",
    "            dflb0 = df(x) + dlb1D(x, a, b)/t\n",
    "            dx = -dflb0\n",
    "            if d2f is not None:\n",
    "                dx = dx / (d2f(x) + d2lb1D(x, a, b)/t)\n",
    "            x = backtracking1D(x, dx, flb, dflb0, alpha=al, beta=be)\n",
    "            pts.append(x)\n",
    "            \n",
    "        if verbose:\n",
    "            s = np.linspace(a+1e-6, b-1e-6, 100)\n",
    "            y = np.zeros(100)\n",
    "            q = np.zeros(len(pts))\n",
    "            for k in range(100):\n",
    "                y[k] = flb(s[k])\n",
    "            for k in range(len(pts)):\n",
    "                q[k] = flb(pts[k])\n",
    "                \n",
    "            fl = min(np.min(q), 0)\n",
    "            fu = max(np.max(q), 0)\n",
    "            \n",
    "            interval_length = np.max(pts) - np.min(pts)\n",
    "            range_length = fu - fl\n",
    "            \n",
    "            l = np.min(pts) - 0.1*interval_length\n",
    "            u = np.max(pts) + 0.1*interval_length\n",
    "            fl = np.min(q) - 0.1*range_length\n",
    "            fu = np.max(q) + 0.1*range_length\n",
    "        \n",
    "            obj, =plt.plot(s, y, label=('Objective plus barrier at t=%f' % t))\n",
    "            bt =plt.scatter(pts, np.zeros(len(pts)), label='Inner loop iterates')\n",
    "            outer =plt.scatter([pts[-1]], 0, label='Outer loop iterate', color='red')\n",
    "            vals =plt.scatter(pts, q, label='Values at iterates')\n",
    "            plt.axis([l, u, min(fl, 0), max(fu, 0)])\n",
    "            plt.legend(handles=[obj, bt, outer, vals])\n",
    "            plt.xlabel('x')\n",
    "            plt.ylabel('f(x) plus barrier')\n",
    "            plt.title('Log barrier steps at outer iteration %d' % i)\n",
    "            plt.show()\n",
    "            \n",
    "    return x\n",
    "\n",
    "a=0.5\n",
    "b=3\n",
    "x0=1\n",
    "f=lambda x: np.exp(x)/(x**2)\n",
    "df=lambda x: f(x) - 2* np.exp(x)/(x**3)\n",
    "\n",
    "x_approx = log_barrier_opt_1D(a, b, x0, f, df, verbose=True, out_iter=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team Problems\n",
    "\n",
    "1. Perform one step of backtracking use steepest descent increments on the function $f(x)=x^4+x^2+1$ with $x^{(0)}=1$.\n",
    "2. Perform one step of backtracking use Newton's method increments on the function $f(x)=x^4+x^2+1$ with $x^{(0)}=1$.\n",
    "2. Perform one step of backtracking using steepest descent increments on the function $f(x)=x^2-\\log(x-1)-\\log(3-x)$ with $x^{(0)}=2$\n",
    "4. Perform one step of backtracking using Newton's method increments on the function $f(x)=x^2-\\log(x-1)-\\log(3-x)$ with $x^{(0)}=2$?\n",
    "5. Perform one step of backtracking using steepest descent increments on the function $f(x)=x^2-\\frac{1}{2}\\log(x-1)-\\frac{1}{2}\\log(3-x)$ with $x^{(0)}=3/2$\n",
    "6. Perform one step of backtracking using Newton's method increments on the function $f(x)=x^2-\\frac{1}{2}\\log(x-1)-\\frac{1}{4}\\log(3-x)$ with $x^{(0)}=3/2$\n",
    "7. Perform one step of backtracking using steepest descent increments on the function $f(x)=x^2-\\frac{1}{4}\\log(x-1)-\\frac{1}{4}\\log(3-x)$ with $x^{(0)}=5/4$\n",
    "8. Perform one step of backtracking using Newton's method  increments on the function $f(x)=x^2-\\frac{1}{4}\\log(x-1)-\\frac{1}{4}\\log(3-x)$ with $x^{(0)}=5/4$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part VIII: Stochastic Descent\n",
    "\n",
    "\n",
    "## Maximum Likelihood Problems\n",
    "\n",
    "We will encounter many optimization problems which have a form analgous to\n",
    "$$\n",
    "\\min_{\\theta\\in\\mathbb{R}} \\frac{1}{N}\\sum_{i=1}^Nf(\\theta;\\:\\theta^{(i)})\n",
    "$$\n",
    "where $f:\\mathbb{R}\\times\\mathbb{R}\\rightarrow\\mathbb{R}$ is a function of a parameter $\\theta$ and a point of data $\\theta^{(i)}$. For example, suppose that we know that each of the data points $\\theta^{(i)}$ is drawn from a **normal distribution** with unknown mean and unit variance? This is denoted $\\theta^{(i)}\\sim \\mathcal{N}(\\bullet;\\theta,1)$. Here, \n",
    "$$\n",
    "\\mathcal{N}(x;\\mu,\\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\n",
    "$$\n",
    "is the probability density function (PDF) of the normal distribution with mean $\\mu\\in\\mathbb{R}$ and variance $\\sigma^2$, and $\\xi\\sim\\mathcal{N}(x;\\mu,\\sigma^2)$ indicates that\n",
    "$$\n",
    "\\text{Prob}(a\\leq \\xi\\leq b) = \\int_a^b \\mathcal{N}(x;\\mu,\\sigma^2)\\:dx.\n",
    "$$\n",
    "The PDF is also referred to as the **likelihood function**. One further assumption is that **each draw of** $\\theta^{(i)}$ **is independent**, and therefore the probability of a simultaneous (rectangular!) event has a multiplicative formula:\n",
    "$$\n",
    "\\text{Prob}\\left(a_i\\leq \\theta^{(i)}\\leq b_i\\text{ for all }i=1,2,\\ldots, N\\right)=\\prod_{i=1}^N \\text{Prob}(a_i\\leq\\theta^{(i)}\\leq b_i).\n",
    "$$\n",
    "Equivalently, the likelihood function of the entire seqence $\\theta^{(1)}, \\theta^{(2)}, \\theta^{(3)}, \\ldots, \\theta^{(N)}$ is\n",
    "$$\n",
    "\\mathcal{L}(\\theta\\:;\\theta^{(1)}, \\theta^{(2)}, \\theta^{(3)}, \\ldots, \\theta^{(N)}) = \\prod_{i=1}^N \\mathcal{N}(\\theta^{(i)};\\theta,1)\n",
    "$$\n",
    "The **maximum likelihood principle** states that the best estimate for the true parameter $\\theta$ given the data is the value which solves\n",
    "$$\n",
    "\\max_{\\theta\\in\\mathbb{R}} \\mathcal{L}(\\theta\\:;\\theta^{(1)}, \\theta^{(2)}, \\theta^{(3)}, \\ldots, \\theta^{(N)}).\n",
    "$$\n",
    "Taking the negative of the logarithm gives us the **negative log-likelihood** function \n",
    "$$\n",
    "\\ell(\\theta\\:;\\theta^{(1)}, \\theta^{(2)}, \\theta^{(3)}, \\ldots, \\theta^{(N)})=-\\log\\mathcal{L}(\\theta\\:;\\theta^{(1)}, \\theta^{(2)}, \\theta^{(3)}, \\ldots, \\theta^{(N)})\n",
    "$$\n",
    "and we quickly see that\n",
    "$$\n",
    "\\ell(\\theta\\:;\\theta^{(1)}, \\theta^{(2)}, \\theta^{(3)}, \\ldots, \\theta^{(N)}) = \\sum_{i=1}^N \\frac{1}{2}\\log(2\\pi) + \\frac{1}{2}(\\theta^{(i)}-\\theta)^2\n",
    "$$\n",
    "since\n",
    "$$\n",
    "-\\log \\mathcal{N}(\\theta^{(i)}\\:;\\theta,\\sigma^2)=-\\log \\frac{1}{\\sqrt{2\\pi}}e^{-\\frac{1}{2}(\\theta^{(i)}-\\theta)^2}=\\frac{1}{2}\\log(2\\pi) +\\frac{1}{2}(\\theta^{(i)}-\\theta)^2.\n",
    "$$\n",
    "The negative log function is **strictly order reversing** and therefore minimization of the negative log-likelihood,\n",
    "$$\n",
    "\\min_{\\theta\\in\\mathbb{R}} \\ell(\\theta\\:;\\theta^{(1)}, \\theta^{(2)}, \\theta^{(3)}, \\ldots, \\theta^{(N)}),\n",
    "$$\n",
    "is equivalent to maximimizing the the original likelihood function. Finally, we note that \n",
    "$$\n",
    "\\min f(x)\\text{ and } \\min af(x)+b\n",
    "$$\n",
    "are equivalent optimization programs for all $a,b\\in\\mathbb{R}$ with $a\\not=0$, and therefore minimization of the negative log-likelihood function is equivalent to\n",
    "$$\n",
    "\\min_{\\theta\\in\\mathbb{R}} \\frac{1}{N}\\sum_{i=1}^N (\\theta^{(i)}-\\theta)^2\n",
    "$$\n",
    "In this particular instance, the optimal value is $\\theta^\\ast=\\frac{1}{N}\\sum_{i=1}^N\\theta^{(i)}$.\n",
    "\n",
    "## Stochastic descent directions\n",
    "\n",
    "Not all such minimization problems are tractable. For example, suppose $y^{(i)}=-1$ or $1$ depends on some real number $x^{(i)}$ so that the conditional probability is\n",
    "$$\n",
    "\\text{Prob}(y^{(i)}=1\\vert\\: x^{(i)};\\alpha)=\\frac{1}{1+e^{-\\alpha x^{(i)}}},\n",
    "$$\n",
    "where $\\alpha$ is some unknown parameter that we need to estimate. Recall that the **logit function** is\n",
    "$$\n",
    "\\text{logit}(x) = \\frac{1}{1+e^{-x}},\n",
    "$$\n",
    "so \n",
    "$$\n",
    "\\text{Prob}(y^{(i)}=1\\vert\\: x^{(i)};\\alpha) = \\text{logit}(\\alpha x^{(i)})\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\text{Prob}(y^{(i)}=-1\\vert\\: x^{(i)};\\alpha) = \\text{logit}(-\\alpha x^{(i)})\n",
    "$$\n",
    "The data we acquire is of the form $(x^{(i)}, y^{(i)})\\in\\mathbb{R}\\times\\{-1,1\\}$. Assuming independence of the draws $y^{(i)}$, the maximum likelihood principle leads us the program\n",
    "$$\n",
    "\\max_{\\alpha\\in\\mathbb{R}} \\prod_{i=1}^N \\text{logit}(\\alpha x^{(i)} y^{(i)}).\n",
    "$$\n",
    "Taking the negative log and rescaling yields the equivalent program\n",
    "$$\n",
    "\\min_{\\alpha\\in\\mathbb{R}} \\frac{1}{N}\\sum_{i=1}^N \\log\\left(1+e^{-\\alpha x^{(i)}y^{(i)}}\\right)\n",
    "$$\n",
    "Let's explore the behavior of the function $\\phi(x)=\\log(1+e^{-x})$. Taking derivatives, we have\n",
    "$$\n",
    "\\phi^\\prime(x) = -\\frac{e^{-x}}{1+e^{-x}} = -\\text{logit}(-x)\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\phi^{\\prime\\prime}(x) = \\frac{e^x}{\\left(1+e^x\\right)^2}=\\text{logit}(x)\\text{logit}(-x).\n",
    "$$\n",
    "Note that this last quantity is always positive, so we have that $\\phi$ is strictly convex on $\\mathbb{R}$. Since\n",
    "$$\n",
    "\\Phi(\\alpha)=\\frac{1}{N}\\sum_{i=1}^N -\\log\\left(1+e^{-\\alpha x^{(i)}y^{(i)}}\\right)=\\frac{1}{N}\\sum_{i=1}^N\\phi\\left(\\alpha x^{(i)}y^{(i)}\\right)\n",
    "$$\n",
    "we see that each $\\phi\\left(\\alpha x^{(i)}y^{(i)}\\right)$ is convex since they are all compositions of a convex function with an affine function, and therefore $\\Phi(\\alpha)$ is convex function since it is a sum of convex functions. From our previous calculations, we also know that\n",
    "$$\n",
    "\\Phi^\\prime(\\alpha) = -\\frac{1}{N}\\sum_{i=1}^N x^{(i)}y^{(i)}\\text{logit}\\left(-\\alpha x^{(i)}y^{(i)}\\right)\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\Phi^{\\prime\\prime}(\\alpha) = \\frac{1}{N}\\sum_{i=1}^N \\left(x^{(i)}y^{(i)}\\right)^2\\text{logit}\\left(-\\alpha x^{(i)}y^{(i)}\\right)\\text{logit}\\left(\\alpha x^{(i)}y^{(i)}\\right)=\\frac{1}{N}\\sum_{i=1}^N\\left(x^{(i)}\\right)^2\\text{logit}\\left(-\\alpha x^{(i)}\\right)\\text{logit}\\left(\\alpha x^{(i)}\\right)\n",
    "$$\n",
    "Solving $\\Phi^\\prime(\\alpha)=0$ is intractable, so this is a perfect candidate for an iterative method. However, we may have a **big data** problem and therefore computation of the full sum may be quite expensive. \n",
    "\n",
    "To overcome our data problem, we will create iterates of the form\n",
    "$$\n",
    "\\alpha^{(k+1)} = \\alpha^{(k)} + \\gamma^{(k)}\\Delta\\alpha^{(k)}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\Delta\\alpha^{(k)} = -\\Phi_Q^\\prime(\\alpha^{(k)})=\\frac{1}{M} \\sum_{j=1}^M x^{(i^{(j)})}y^{(i^{(j)})}\\text{logit}\\left(-\\alpha^{(k)}x^{(i^{(j)})}y^{(i^{(j)})}\\right)\n",
    "$$\n",
    "and $Q=\\{i^{(1)}, i^{(2)}, i^{(3)},\\ldots,i^{(M)}\\}\\subset\\{1,2,3,\\ldots, N\\}$ is a random subset of the indices from $1$ to $N$. The reason we expect this to work is because the **expected value** of $\\Delta\\alpha^{(k)}$ is the steepest descent increment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy.random as rd\n",
    "\n",
    "def logit(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def phi(x):\n",
    "    return np.log(1+np.exp(-x))\n",
    "\n",
    "def dphi(x):\n",
    "    return -logit(-x)\n",
    "\n",
    "def d2phi(x):\n",
    "    return logit(x) * logit(-x)\n",
    "\n",
    "def rand_logit_data(alpha, N, num_nodes=25):\n",
    "    X = rd.randn(num_nodes)\n",
    "    x = np.zeros(N)\n",
    "    y = np.zeros(N)\n",
    "    \n",
    "    for i in range(N):\n",
    "        k = rd.choice(num_nodes) # pick one random index\n",
    "        p = rd.rand()\n",
    "        x[i] = X[k]\n",
    "        if p < logit(alpha*x[i]):\n",
    "            y[i] = 1\n",
    "        else:\n",
    "            y[i] = -1\n",
    "            \n",
    "    return x, y\n",
    "\n",
    "N = 1000000 # 1 Million data points\n",
    "M = 10000 # Use 10,000 data points in each stochastic step\n",
    "alpha_ast = 1.0\n",
    "steps = 100\n",
    "\n",
    "x, y = rand_logit_data(alpha_ast, N)\n",
    "alpha_0 = 10.0\n",
    "\n",
    "s = np.linspace(-10, 10, 100)\n",
    "obj_fun = np.zeros(100)\n",
    "d_obj_fun = np.zeros(100)\n",
    "for i in range(100):\n",
    "    obj_fun[i] = np.mean(phi(s[i] * x * y))\n",
    "    d_obj_fun[i] = np.mean(x*y*dphi(s[i] * x * y))\n",
    "\n",
    "plt.plot([-10, 10], [0, 0], 'k--')\n",
    "fun_plt, =plt.plot(s, obj_fun, label='Negative Log-Likelihood')\n",
    "dfun_plt, =plt.plot(s, d_obj_fun, label='Derivative')\n",
    "plt.legend(handles=[fun_plt, dfun_plt])\n",
    "plt.xlabel('x')\n",
    "plt.title('Full objective function and derivative')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Illustrate distribution of steepest descent increments\n",
    "d_alphas_0 = []\n",
    "for i in range(1000):\n",
    "    Q = rd.choice(N, M, replace=True) # Draw indices without replacement\n",
    "    d_alphas_0.append(-np.mean(x[Q]*y[Q]*dphi(alpha_0 * x[Q] * y[Q])))\n",
    "    \n",
    "d_alpha_0 = -np.mean(x*y*dphi(alpha_0 * x * y))\n",
    "\n",
    "plt.hist(d_alphas_0, bins=25)\n",
    "plt.scatter([d_alpha_0], [0], color='orange')\n",
    "plt.scatter([np.mean(d_alphas_0)], [0], color='black')\n",
    "plt.xlabel('$-\\Phi_Q^\\prime(a)$ with a=%.2f' % alpha_0)\n",
    "plt.ylabel('Bin Counts')\n",
    "plt.title('Distribution of steepest discent increments')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "alpha = alpha_0\n",
    "errs = []\n",
    "for i in range(steps):\n",
    "    Q = rd.choice(N, M, replace=False) # Draw indices without replacement\n",
    "    d_alpha = -np.mean(x[Q]*y[Q]*dphi(alpha * x[Q] * y[Q]))\n",
    "    alpha = alpha + np.sqrt(M)*d_alpha/(i+1)\n",
    "    errs.append(np.abs(alpha-alpha_ast))\n",
    "\n",
    "plt.semilogy(errs)\n",
    "plt.xlabel('Iteration Index')\n",
    "plt.ylabel('Error')\n",
    "plt.title('Error at each iteration')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Team Problems\n",
    "\n",
    "1. What happens if we use the log barrier method to optimize $f$ over $[0,1]$, but initialize with $x^{(0)}=2$?\n",
    "2. If $f$ is convex over $[a, b]$, explain why $f(x)-\\frac{1}{t}\\log(x-a)-\\frac{1}{t}\\log(b-x)$ is a convex function over $[a, b]$ for any $t>0$.\n",
    "3. Suppose $f\\in C^2([a, b])$ and let $x(t) = \\arg\\min f(x)-\\frac{1}{t}\\log(x-a)-\\frac{1}{t}\\log(b-x)$ ($x(t)$ is called the **central path**). Explain why either $\\lim_{t\\rightarrow\\infty} x(t)=a$, $\\lim_{t\\rightarrow\\infty} x(t)=b$, or $\\lim_{t\\rightarrow\\infty} f^\\prime(x(t))=0$. In particular, this can be used to show that the limit of the central path is always a solution if $f$ is convex.\n",
    "4. Consider the central path from problem 3. Is it true that $f(x(t)) < f(x(s))$ for all $0<t<s$?\n",
    "5. Given data $\\{\\theta^{(i)}\\}_{i=1}^N$ drawn from $\\mathcal{N}(\\bullet;0,\\theta^2)$ (that is, a normal with zero mean and unkown variance), what is the maximum likelihood estimator for $\\theta$?\n",
    "6. Since stochastic descent does not necessarily produce iterates with monotone decreasing iterate values, what should we do to get a \"good\" approximate solution from the iterates?\n",
    "7. In the above code, we use $\\gamma^{(k)} = \\frac{\\sqrt{M}}{k+1}$. Why is it okay to inflate the quantity by the factor $\\sqrt{M}$? Thinking back to probability and statistics, where does $\\sqrt{M}$ come from?\n",
    "8. Suppose we are able to guarantee that $\\lim_{k\\rightarrow\\infty}\\Phi^\\prime(\\alpha^{(k)})=0$ with probability $1$ for the iterates from stochastic gradient descent. What does this imply about the limit of the iterates for logisitic regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
